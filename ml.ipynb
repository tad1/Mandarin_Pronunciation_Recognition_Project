{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 20:38:09.661854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747852689.838468    2315 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747852689.877488    2315 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747852690.152372    2315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747852690.152395    2315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747852690.152397    2315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747852690.152398    2315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-21 20:38:10.174717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 512\n",
    "SLIDE_SIZE = 256\n",
    "NUM_CLASSES = 5\n",
    "model = keras.Sequential([\n",
    "    layers.LSTM(NUM_CLASSES, return_sequences=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.random.rand(1, 512, 1).astype(np.float32)\n",
    "res = model(input)\n",
    "res.shape\n",
    "\n",
    "input = np.random.rand(1, 100, 1).astype(np.float32)\n",
    "res = model(input)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 out of 1000\n",
      "Processing 10 out of 1000\n",
      "Processing 20 out of 1000\n",
      "Processing 30 out of 1000\n",
      "Processing 40 out of 1000\n",
      "Processing 50 out of 1000\n",
      "Processing 60 out of 1000\n",
      "Processing 70 out of 1000\n",
      "Processing 80 out of 1000\n",
      "Processing 90 out of 1000\n",
      "Processing 100 out of 1000\n",
      "Processing 110 out of 1000\n",
      "Processing 120 out of 1000\n",
      "Processing 130 out of 1000\n",
      "Processing 140 out of 1000\n",
      "Processing 150 out of 1000\n",
      "Processing 160 out of 1000\n",
      "Processing 170 out of 1000\n",
      "Processing 180 out of 1000\n",
      "Processing 190 out of 1000\n",
      "Processing 200 out of 1000\n",
      "Processing 210 out of 1000\n",
      "Processing 220 out of 1000\n",
      "Processing 230 out of 1000\n",
      "Processing 240 out of 1000\n",
      "Processing 250 out of 1000\n",
      "Processing 260 out of 1000\n",
      "Processing 270 out of 1000\n",
      "Processing 280 out of 1000\n",
      "Processing 290 out of 1000\n",
      "Processing 300 out of 1000\n",
      "Processing 310 out of 1000\n",
      "Processing 320 out of 1000\n",
      "Processing 330 out of 1000\n",
      "Processing 340 out of 1000\n",
      "Processing 350 out of 1000\n",
      "Processing 360 out of 1000\n",
      "Processing 370 out of 1000\n",
      "Processing 380 out of 1000\n",
      "Processing 390 out of 1000\n",
      "Processing 400 out of 1000\n",
      "Processing 410 out of 1000\n",
      "Processing 420 out of 1000\n",
      "Processing 430 out of 1000\n",
      "Processing 440 out of 1000\n",
      "Processing 450 out of 1000\n",
      "Processing 460 out of 1000\n",
      "Processing 470 out of 1000\n",
      "Processing 480 out of 1000\n",
      "Processing 490 out of 1000\n",
      "Processing 500 out of 1000\n",
      "Processing 510 out of 1000\n",
      "Processing 520 out of 1000\n",
      "Processing 530 out of 1000\n",
      "Processing 540 out of 1000\n",
      "Processing 550 out of 1000\n",
      "Processing 560 out of 1000\n",
      "Processing 570 out of 1000\n",
      "Processing 580 out of 1000\n",
      "Processing 590 out of 1000\n",
      "Processing 600 out of 1000\n",
      "Processing 610 out of 1000\n",
      "Processing 620 out of 1000\n",
      "Processing 630 out of 1000\n",
      "Processing 640 out of 1000\n",
      "Processing 650 out of 1000\n",
      "Processing 660 out of 1000\n",
      "Processing 670 out of 1000\n",
      "Processing 680 out of 1000\n",
      "Processing 690 out of 1000\n",
      "Processing 700 out of 1000\n",
      "Processing 710 out of 1000\n",
      "Processing 720 out of 1000\n",
      "Processing 730 out of 1000\n",
      "Processing 740 out of 1000\n",
      "Processing 750 out of 1000\n",
      "Processing 760 out of 1000\n",
      "Processing 770 out of 1000\n",
      "Processing 780 out of 1000\n",
      "Processing 790 out of 1000\n",
      "Processing 800 out of 1000\n",
      "Processing 810 out of 1000\n",
      "Processing 820 out of 1000\n",
      "Processing 830 out of 1000\n",
      "Processing 840 out of 1000\n",
      "Processing 850 out of 1000\n",
      "Processing 860 out of 1000\n",
      "Processing 870 out of 1000\n",
      "Processing 880 out of 1000\n",
      "Processing 890 out of 1000\n",
      "Processing 900 out of 1000\n",
      "Processing 910 out of 1000\n",
      "Processing 920 out of 1000\n",
      "Processing 930 out of 1000\n",
      "Processing 940 out of 1000\n",
      "Processing 950 out of 1000\n",
      "Processing 960 out of 1000\n",
      "Processing 970 out of 1000\n",
      "Processing 980 out of 1000\n",
      "Processing 990 out of 1000\n"
     ]
    }
   ],
   "source": [
    "from get_dataset import get_dataset\n",
    "dataset = get_dataset(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, labels = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [261.4938  ]\n",
      "  [242.90895 ]\n",
      "  [239.74968 ]\n",
      "  [238.47888 ]\n",
      "  [236.40579 ]\n",
      "  [235.56746 ]\n",
      "  [235.68184 ]\n",
      "  [236.38797 ]\n",
      "  [238.01611 ]\n",
      "  [238.84811 ]\n",
      "  [240.26314 ]\n",
      "  [241.60866 ]\n",
      "  [242.64944 ]\n",
      "  [243.02704 ]\n",
      "  [242.74783 ]\n",
      "  [241.23889 ]\n",
      "  [238.9653  ]\n",
      "  [235.1132  ]\n",
      "  [230.35332 ]\n",
      "  [227.08939 ]\n",
      "  [221.3979  ]\n",
      "  [215.46255 ]\n",
      "  [211.66489 ]\n",
      "  [207.23666 ]\n",
      "  [204.17459 ]\n",
      "  [201.55823 ]\n",
      "  [200.92896 ]\n",
      "  [200.47931 ]\n",
      "  [200.30882 ]\n",
      "  [205.33849 ]\n",
      "  [211.03319 ]\n",
      "  [214.03421 ]\n",
      "  [216.28156 ]\n",
      "  [217.41978 ]\n",
      "  [215.71547 ]\n",
      "  [227.04771 ]\n",
      "  [238.4628  ]\n",
      "  [240.76675 ]\n",
      "  [242.72882 ]\n",
      "  [244.3265  ]\n",
      "  [245.77444 ]\n",
      "  [246.3649  ]\n",
      "  [246.21828 ]\n",
      "  [245.37093 ]\n",
      "  [243.54378 ]\n",
      "  [240.4168  ]\n",
      "  [237.5361  ]\n",
      "  [233.62943 ]\n",
      "  [229.09712 ]\n",
      "  [226.07819 ]\n",
      "  [221.43242 ]\n",
      "  [215.52216 ]\n",
      "  [212.5725  ]\n",
      "  [209.6907  ]\n",
      "  [207.98798 ]\n",
      "  [207.19409 ]\n",
      "  [205.85086 ]\n",
      "  [  0.      ]\n",
      "  [110.56747 ]\n",
      "  [108.57432 ]\n",
      "  [129.3945  ]\n",
      "  [124.324745]\n",
      "  [125.636024]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [508.07803 ]\n",
      "  [507.31778 ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [247.91414 ]\n",
      "  [248.5764  ]\n",
      "  [247.71652 ]\n",
      "  [247.24783 ]\n",
      "  [248.16313 ]\n",
      "  [249.03545 ]\n",
      "  [249.75554 ]\n",
      "  [248.81848 ]\n",
      "  [242.86534 ]\n",
      "  [241.32635 ]\n",
      "  [243.19072 ]\n",
      "  [244.18481 ]\n",
      "  [243.5149  ]\n",
      "  [242.85573 ]\n",
      "  [241.79857 ]\n",
      "  [242.26463 ]\n",
      "  [241.21733 ]\n",
      "  [241.02454 ]\n",
      "  [241.0148  ]\n",
      "  [240.76553 ]\n",
      "  [239.32556 ]\n",
      "  [239.48595 ]\n",
      "  [240.70534 ]\n",
      "  [240.909   ]\n",
      "  [241.36209 ]\n",
      "  [242.75659 ]\n",
      "  [244.23187 ]\n",
      "  [243.38339 ]\n",
      "  [243.19304 ]\n",
      "  [245.43748 ]\n",
      "  [245.24548 ]\n",
      "  [245.24243 ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [291.17307 ]\n",
      "  [270.98257 ]\n",
      "  [261.6316  ]\n",
      "  [258.3478  ]\n",
      "  [254.44707 ]\n",
      "  [250.00685 ]\n",
      "  [242.82533 ]\n",
      "  [236.92725 ]\n",
      "  [231.91855 ]\n",
      "  [228.28667 ]\n",
      "  [224.86089 ]\n",
      "  [221.3347  ]\n",
      "  [216.76875 ]\n",
      "  [214.13112 ]\n",
      "  [210.84125 ]\n",
      "  [210.50629 ]\n",
      "  [209.83185 ]\n",
      "  [208.10883 ]\n",
      "  [206.40025 ]\n",
      "  [204.90189 ]\n",
      "  [202.95044 ]\n",
      "  [200.49405 ]\n",
      "  [199.79318 ]\n",
      "  [200.58372 ]\n",
      "  [201.58868 ]\n",
      "  [201.95302 ]\n",
      "  [202.98079 ]\n",
      "  [204.39212 ]\n",
      "  [205.27339 ]\n",
      "  [207.55214 ]\n",
      "  [209.9905  ]\n",
      "  [209.86603 ]\n",
      "  [209.07771 ]\n",
      "  [209.71158 ]\n",
      "  [210.28296 ]\n",
      "  [212.47255 ]\n",
      "  [213.01544 ]\n",
      "  [209.63353 ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [224.5921  ]\n",
      "  [227.36633 ]\n",
      "  [214.1845  ]\n",
      "  [207.71915 ]\n",
      "  [201.45801 ]\n",
      "  [196.37271 ]\n",
      "  [193.60191 ]\n",
      "  [191.69533 ]\n",
      "  [189.1229  ]\n",
      "  [253.76627 ]\n",
      "  [261.4555  ]\n",
      "  [232.03658 ]\n",
      "  [225.22366 ]\n",
      "  [229.80692 ]\n",
      "  [234.43205 ]\n",
      "  [228.44962 ]\n",
      "  [220.49893 ]\n",
      "  [222.97044 ]\n",
      "  [224.7012  ]\n",
      "  [225.69661 ]\n",
      "  [224.22063 ]\n",
      "  [220.10045 ]\n",
      "  [218.93335 ]\n",
      "  [218.26187 ]\n",
      "  [216.67976 ]\n",
      "  [214.40457 ]\n",
      "  [213.90736 ]\n",
      "  [214.92403 ]\n",
      "  [217.91556 ]\n",
      "  [219.67213 ]\n",
      "  [222.23853 ]\n",
      "  [227.17953 ]\n",
      "  [229.3393  ]\n",
      "  [222.08098 ]\n",
      "  [259.4382  ]\n",
      "  [246.59737 ]\n",
      "  [241.95338 ]\n",
      "  [238.72815 ]\n",
      "  [238.21097 ]\n",
      "  [231.55418 ]\n",
      "  [225.45432 ]\n",
      "  [219.70995 ]\n",
      "  [216.88065 ]\n",
      "  [215.86938 ]\n",
      "  [216.10185 ]\n",
      "  [217.867   ]\n",
      "  [218.70381 ]\n",
      "  [218.48935 ]\n",
      "  [216.5952  ]\n",
      "  [216.16357 ]\n",
      "  [216.69476 ]\n",
      "  [214.52715 ]\n",
      "  [214.8692  ]\n",
      "  [214.80049 ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [227.2029  ]\n",
      "  [234.00374 ]\n",
      "  [228.57285 ]\n",
      "  [224.12549 ]\n",
      "  [110.78091 ]\n",
      "  [109.806366]\n",
      "  [106.50111 ]\n",
      "  [105.291374]\n",
      "  [104.6542  ]\n",
      "  [105.02156 ]\n",
      "  [105.55734 ]\n",
      "  [106.48213 ]\n",
      "  [106.35593 ]\n",
      "  [104.69318 ]\n",
      "  [106.07311 ]\n",
      "  [104.3257  ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [250.00853 ]\n",
      "  [240.48923 ]\n",
      "  [238.11243 ]\n",
      "  [235.59836 ]\n",
      "  [230.43373 ]\n",
      "  [221.6911  ]\n",
      "  [215.11287 ]\n",
      "  [204.05836 ]\n",
      "  [199.36852 ]\n",
      "  [197.47974 ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]\n",
      "  [  0.      ]]], shape=(1, 445, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def pre_process(list, batch_size):\n",
    "    value = tf.convert_to_tensor([val if val != None else 0 for val in list])\n",
    "    return tf.reshape(value, (1, -1, 1))\n",
    "    #padding_size = batch_size - (int(tf.shape(value)[0]) % batch_size)\n",
    "    #value = tf.reshape(value, (1, -1, 1))\n",
    "    #paddings = tf.convert_to_tensor([[0, 0], [0, padding_size], [0, 0]])\n",
    "    #padded = tf.pad(value, paddings, constant_values=np.nan)\n",
    "    #divisions = tf.shape(padded)[1] // batch_size\n",
    "\n",
    "    #print(divisions)\n",
    "    #splits = tf.split(padded, int(divisions), axis=1)\n",
    "    #return splits\n",
    "\n",
    "val = pre_process(values[0], 215)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Tone.TONE2: 2>, <Tone.TONE3: 3>, <Tone.TONE1: 1>, <Tone.TONE1: 1>, <Tone.TONE1: 1>, <Tone.TONE1: 1>, <Tone.TONE2: 2>, <Tone.TONE3: 3>, <Tone.TONE4: 4>, <Tone.TONE4: 4>, <Tone.TONE2: 2>, <Tone.TONE4: 4>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([2, 3, 1, 1, 1, 1, 2, 3, 4, 4, 2, 4], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_process_labels(enums):\n",
    "    value = tf.convert_to_tensor([val.value for val in enums])\n",
    "    return value\n",
    "\n",
    "print(labels[0])\n",
    "pre_process_labels(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m EPOCHS = \u001b[32m10\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_values = \u001b[43mvalues\u001b[49m[:\u001b[32m200\u001b[39m]\n\u001b[32m      3\u001b[39m train_labels = labels[:\u001b[32m200\u001b[39m]\n\u001b[32m      4\u001b[39m validation_values = values[\u001b[32m201\u001b[39m:]\n",
      "\u001b[31mNameError\u001b[39m: name 'values' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "train_values = values[:200]\n",
    "train_labels = labels[:200]\n",
    "validation_values = values[201:]\n",
    "validation_labels = labels[201:]\n",
    "loss_fn = tf.nn.ctc_loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for val, lab in zip(train_values, train_labels):\n",
    "        # convert to tensors\n",
    "        val = pre_process(val, WINDOW_SIZE)\n",
    "        lab = pre_process_labels(lab)\n",
    "        lab = tf.reshape(lab, (1, -1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(val)\n",
    "            print(predictions.shape)\n",
    "            loss = loss_fn(lab, predictions)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        # validate\n",
    "        val = pre_process(validation_values[0], WINDOW_SIZE)\n",
    "        lab = pre_process_labels(validation_labels[0])\n",
    "        lab = tf.reshape(lab, (1, -1))\n",
    "        predictions = model(val)\n",
    "        loss = loss_fn(lab, predictions)\n",
    "        print(f\"Validation Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
