{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd77cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import polars as pl\n",
    "from typing import Callable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Model and Data structures\n",
    "from models.FusionCNN import ContextFusionCNN\n",
    "from data.source.pg_experiment import get_example_dataframe\n",
    "from dataset import Cast, TorchDataset\n",
    "from pytorch_dataloader import build_collate_fn, PaddingCollate, DefaultCollate, MemoryLoadedDataLoader\n",
    "from transformation import Channels, RMSEnergy, TorchVadMFCC, ZeroCrossingRate\n",
    "\n",
    "# Environment setup\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f317736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 7\n",
      "Number of samples: 48\n"
     ]
    }
   ],
   "source": [
    "df_pron, df_tone = get_example_dataframe()\n",
    "\n",
    "# Get the target words with val accuracy above 70%\n",
    "TARGET_WORDS = [\"a0\", \"a1\", \"a100\", \"a2\", \"a3\", \"a5\", \"a8\"]\n",
    "dataframe = df_pron.filter(pl.col(\"word_id\").is_in(TARGET_WORDS))\n",
    "\n",
    "dataframe = dataframe.with_columns([\n",
    "    pl.struct(\"word_id\").rank(\"dense\").alias(\"word_id\"),\n",
    "    pl.col(\"value\").cast(pl.Float32) \n",
    "])\n",
    "dataframe = dataframe.filter((pl.col(\"stage\") == 1))\n",
    "\n",
    "N_WORDS = dataframe.select(pl.col(\"word_id\").n_unique()).item()\n",
    "print(f\"Number of unique words: {N_WORDS}\")\n",
    "print(f\"Number of samples: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df27507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id_student</th><th>value</th><th>word_id</th><th>rec_path</th><th>stage</th></tr><tr><td>i64</td><td>f32</td><td>u32</td><td>str</td><td>i32</td></tr></thead><tbody><tr><td>1603</td><td>1.0</td><td>1</td><td>&quot;/home/kamil2002/Mandarin_Pronu…</td><td>1</td></tr><tr><td>1580</td><td>1.0</td><td>1</td><td>&quot;/home/kamil2002/Mandarin_Pronu…</td><td>1</td></tr><tr><td>1593</td><td>1.0</td><td>1</td><td>&quot;/home/kamil2002/Mandarin_Pronu…</td><td>1</td></tr><tr><td>1686</td><td>0.0</td><td>1</td><td>&quot;/home/kamil2002/Mandarin_Pronu…</td><td>1</td></tr><tr><td>1687</td><td>1.0</td><td>1</td><td>&quot;/home/kamil2002/Mandarin_Pronu…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────┬───────┬─────────┬─────────────────────────────────┬───────┐\n",
       "│ id_student ┆ value ┆ word_id ┆ rec_path                        ┆ stage │\n",
       "│ ---        ┆ ---   ┆ ---     ┆ ---                             ┆ ---   │\n",
       "│ i64        ┆ f32   ┆ u32     ┆ str                             ┆ i32   │\n",
       "╞════════════╪═══════╪═════════╪═════════════════════════════════╪═══════╡\n",
       "│ 1603       ┆ 1.0   ┆ 1       ┆ /home/kamil2002/Mandarin_Pronu… ┆ 1     │\n",
       "│ 1580       ┆ 1.0   ┆ 1       ┆ /home/kamil2002/Mandarin_Pronu… ┆ 1     │\n",
       "│ 1593       ┆ 1.0   ┆ 1       ┆ /home/kamil2002/Mandarin_Pronu… ┆ 1     │\n",
       "│ 1686       ┆ 0.0   ┆ 1       ┆ /home/kamil2002/Mandarin_Pronu… ┆ 1     │\n",
       "│ 1687       ┆ 1.0   ┆ 1       ┆ /home/kamil2002/Mandarin_Pronu… ┆ 1     │\n",
       "└────────────┴───────┴─────────┴─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058f2c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40, 80])\n",
      "torch.Size([1, 2, 160])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "to_dataset: Callable[[pl.DataFrame], TorchDataset] = lambda dataframe: TorchDataset(\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"stack\",\"multiply\")(\n",
    "            TorchVadMFCC(delta=0),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"cat\",\"multiply\")(\n",
    "            ZeroCrossingRate(),\n",
    "            RMSEnergy(),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"word_id\"), lambda x: torch.tensor(x-1, dtype=torch.long)),\n",
    "    Cast(dataframe.get_column(\"value\"), lambda x: torch.tensor(x).float()),\n",
    ")\n",
    "\n",
    "collate_fn = build_collate_fn(\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=80, pad_dim=2),\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=160, pad_dim=1),\n",
    "    DefaultCollate(),\n",
    "    DefaultCollate(),\n",
    ")\n",
    "\n",
    "\n",
    "dataset_demo = to_dataset(dataframe)\n",
    "\n",
    "#note, if you are using Windows you MUST set `num_workers=0` - TL;DT multithreading DON'T work in notebooks because Windows DON'T have `fork()`\n",
    "num_workers = 0 if os.name == \"nt\" else 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "demo_loader = DataLoader(dataset_demo, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "demo_loader = MemoryLoadedDataLoader(demo_loader, device=device)\n",
    "\n",
    "for x in next(iter(demo_loader)):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e765766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully loaded and is ready for testing.\n"
     ]
    }
   ],
   "source": [
    "from models.FusionCNN import ContextFusionCNN\n",
    "\n",
    "model = ContextFusionCNN(1, 2, num_words=N_WORDS).to(device)\n",
    "\n",
    "model_path = \"ContextFusionCNN.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model has been successfully loaded and is ready for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b20807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student ID   | Word     | Expert       | Model        | Status\n",
      "-----------------------------------------------------------------\n",
      "1603         | 1        | Correct      | Correct      | ✅\n",
      "1580         | 1        | Correct      | Correct      | ✅\n",
      "1593         | 1        | Correct      | Correct      | ✅\n",
      "1686         | 1        | Incorrect    | Correct      | ❌\n",
      "1687         | 1        | Correct      | Incorrect    | ❌\n",
      "1699         | 1        | Correct      | Correct      | ✅\n",
      "1615         | 1        | Incorrect    | Correct      | ❌\n",
      "1603         | 2        | Correct      | Incorrect    | ❌\n",
      "1580         | 2        | Correct      | Correct      | ✅\n",
      "1593         | 2        | Incorrect    | Incorrect    | ✅\n",
      "1686         | 2        | Incorrect    | Incorrect    | ✅\n",
      "1687         | 2        | Correct      | Correct      | ✅\n",
      "1699         | 2        | Correct      | Correct      | ✅\n",
      "1615         | 2        | Correct      | Correct      | ✅\n",
      "1603         | 4        | Correct      | Incorrect    | ❌\n",
      "1580         | 4        | Incorrect    | Correct      | ❌\n",
      "1593         | 4        | Incorrect    | Incorrect    | ✅\n",
      "1686         | 4        | Incorrect    | Incorrect    | ✅\n",
      "1687         | 4        | Incorrect    | Correct      | ❌\n",
      "1699         | 4        | Incorrect    | Correct      | ❌\n",
      "1615         | 4        | Correct      | Incorrect    | ❌\n",
      "1603         | 5        | Correct      | Correct      | ✅\n",
      "1580         | 5        | Correct      | Correct      | ✅\n",
      "1593         | 5        | Correct      | Correct      | ✅\n",
      "1686         | 5        | Correct      | Correct      | ✅\n",
      "1687         | 5        | Correct      | Correct      | ✅\n",
      "1699         | 5        | Correct      | Correct      | ✅\n",
      "1615         | 5        | Correct      | Correct      | ✅\n",
      "1580         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1593         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1686         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1687         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1699         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1615         | 6        | Incorrect    | Incorrect    | ✅\n",
      "1603         | 7        | Incorrect    | Incorrect    | ✅\n",
      "1580         | 7        | Correct      | Incorrect    | ❌\n",
      "1593         | 7        | Incorrect    | Incorrect    | ✅\n",
      "1686         | 7        | Correct      | Correct      | ✅\n",
      "1687         | 7        | Correct      | Correct      | ✅\n",
      "1699         | 7        | Correct      | Correct      | ✅\n",
      "1615         | 7        | Correct      | Correct      | ✅\n",
      "1603         | 3        | Correct      | Correct      | ✅\n",
      "1580         | 3        | Correct      | Correct      | ✅\n",
      "1593         | 3        | Incorrect    | Incorrect    | ✅\n",
      "1686         | 3        | Correct      | Correct      | ✅\n",
      "1687         | 3        | Correct      | Correct      | ✅\n",
      "1699         | 3        | Correct      | Correct      | ✅\n",
      "1615         | 3        | Correct      | Correct      | ✅\n",
      "-----------------------------------------------------------------\n",
      "FINAL DEMO ACCURACY: 79.17%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "correct_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(demo_loader):\n",
    "        # Unpack the batch\n",
    "        x_mfcc, x_context, word_ids, targets = batch\n",
    "        \n",
    "        # Model Forward Pass\n",
    "        output = model(x_mfcc, x_context, word_ids)\n",
    "        \n",
    "        # Decision logic (Threshold 0.5)\n",
    "        prediction = 1 if output.item() > 0.5 else 0\n",
    "        target = int(targets.item())\n",
    "        \n",
    "        # Track accuracy\n",
    "        if prediction == target:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        # Get metadata for the printout\n",
    "        original_row = dataframe.row(i, named=True)\n",
    "        \n",
    "        results.append({\n",
    "            \"Student ID\": original_row[\"id_student\"],\n",
    "            \"Word\": original_row[\"word_id\"],\n",
    "            \"Expert\": \"Correct\" if target == 1 else \"Incorrect\",\n",
    "            \"Model\": \"Correct\" if prediction == 1 else \"Incorrect\",\n",
    "            \"Status\": \"✅\" if prediction == target else \"❌\"\n",
    "        })\n",
    "\n",
    "# Final Accuracy Calculation\n",
    "final_accuracy = correct_predictions / len(dataframe)\n",
    "\n",
    "# Display the results\n",
    "print(f\"{'Student ID':<12} | {'Word':<8} | {'Expert':<12} | {'Model':<12} | {'Status'}\")\n",
    "print(\"-\" * 65)\n",
    "for res in results:\n",
    "    print(f\"{res['Student ID']:<12} | {res['Word']:<8} | \"\n",
    "          f\"{res['Expert']:<12} | {res['Model']:<12} | {res['Status']}\")\n",
    "\n",
    "print(\"-\" * 65)\n",
    "print(f\"FINAL DEMO ACCURACY: {final_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mandarin_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
