{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12f8129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:06:49.748097Z",
     "start_time": "2025-07-29T09:06:49.733744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data.source.pg_experiment import get_pg_experiment_dataframe\n",
    "import polars as pl\n",
    "\n",
    "from models.SimplifiedLightweightCNN import SimplifiedLightweightCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport models.SimplifiedLightweightCNN\n",
    "from models.SimpleCNN_v2 import train, evaluate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from path import RESULT_DIRECTORY\n",
    "import wandb\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57adc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.391376Z",
     "start_time": "2025-07-29T09:04:37.356941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 7\n",
      "Number of samples: 3527\n"
     ]
    }
   ],
   "source": [
    "df_pron, df_tone = get_pg_experiment_dataframe(\".ogg\")\n",
    "\n",
    "# Get the target words with val accuracy above 70%\n",
    "TARGET_WORDS = [\"a0\", \"a1\", \"a100\", \"a2\", \"a3\", \"a5\", \"a8\"]\n",
    "dataframe = df_pron.filter(pl.col(\"word_id\").is_in(TARGET_WORDS))\n",
    "\n",
    "dataframe = dataframe.with_columns([\n",
    "    pl.struct(\"word_id\").rank(\"dense\").alias(\"word_id\"),\n",
    "    pl.col(\"value\").cast(pl.Float32) \n",
    "])\n",
    "\n",
    "# Filters\n",
    "dataframe = dataframe.filter((pl.col(\"stage\") == 1))\n",
    "\n",
    "N_WORDS = dataframe.select(pl.col(\"word_id\").n_unique()).item()\n",
    "print(f\"Number of unique words: {N_WORDS}\")\n",
    "print(f\"Number of samples: {dataframe.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a95dcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.442136Z",
     "start_time": "2025-07-29T09:04:37.416770Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def stratified_split(df: pl.DataFrame, label_col: str, train_frac=0.8, val_frac=0.1, seed=42) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    classes = df.select(label_col).unique().to_series()\n",
    "    train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    for cls in classes:\n",
    "        class_df = df.filter(pl.col(label_col) == cls)\n",
    "        n = class_df.height\n",
    "        indices = rng.permutation(n)\n",
    "\n",
    "        train_end = int(train_frac * n)\n",
    "        val_end = int((train_frac + val_frac) * n)\n",
    "\n",
    "        train_rows.append(class_df[indices[:train_end]])\n",
    "        val_rows.append(class_df[indices[train_end:val_end]])\n",
    "        test_rows.append(class_df[indices[val_end:]])\n",
    "\n",
    "    train_df = pl.concat(train_rows)\n",
    "    val_df = pl.concat(val_rows)\n",
    "    test_df = pl.concat(test_rows)\n",
    "\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd331ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.500687Z",
     "start_time": "2025-07-29T09:04:37.486859Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from polars import DataFrame\n",
    "from dataset import Cast, TorchDataset\n",
    "from develop import reload_function, reload_module\n",
    "import pytorch_dataloader\n",
    "reload_module(pytorch_dataloader)\n",
    "from pytorch_dataloader import ReshapeCollate, build_collate_fn, PaddingCollate, DefaultCollate\n",
    "from functools import partial\n",
    "\n",
    "from transformation import Channels, RMSEnergy, TorchVadLogMelSpec, TorchVadMFCC, ZeroCrossingRate\n",
    "\n",
    "reload_function(TorchVadMFCC)\n",
    "\n",
    "TRAIN_SPLIT = 0.6\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT - VAL_SPLIT\n",
    "train_pl, val_pl, test_pl = stratified_split(dataframe, label_col=\"value\", train_frac=TRAIN_SPLIT, val_frac=VAL_SPLIT)\n",
    "\n",
    "to_dataset: Callable[[DataFrame], TorchDataset] = lambda dataframe: TorchDataset(\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"stack\",\"multiply\")(\n",
    "            TorchVadMFCC(delta=0),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"cat\",\"multiply\")(\n",
    "            ZeroCrossingRate(),\n",
    "            RMSEnergy(),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"word_id\"), lambda x: torch.tensor(x-1, dtype=torch.long)),\n",
    "    Cast(dataframe.get_column(\"value\"), lambda x: torch.tensor(x).float()),\n",
    ")\n",
    "\n",
    "collate_fn = build_collate_fn(\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=80, pad_dim=2),\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=160, pad_dim=1),\n",
    "    DefaultCollate(),\n",
    "    DefaultCollate(),\n",
    ")\n",
    "dataset_train = to_dataset(train_pl)\n",
    "dataset_val = to_dataset(val_pl)\n",
    "dataset_test = to_dataset(test_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be889768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/774/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/589/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/523/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1059/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a2.ogg has no speech segments, using full waveform\n",
      "torch.Size([16, 1, 40, 80])\n",
      "torch.Size([16, 2, 160])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_dataloader import MemoryLoadedDataLoader\n",
    "from os import name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#note, if you are using Windows you MUST set `num_workers=0` - TL;DT multithreading DON'T work in notebooks because Windows DON'T have `fork()`\n",
    "num_workers = 0 if name == \"nt\" else 4\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "for x in next(iter(train_loader)):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf890d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:05:23.032498Z",
     "start_time": "2025-07-29T09:04:37.522932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/589/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/655/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/620/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1021/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1338/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1366/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/411/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1076/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1059/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1460/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/729/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/765/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/594/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/774/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/697/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/505/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1543/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/505/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/523/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/61/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1375/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/947/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a8.ogg has no speech segments, using full waveform\n",
      "Loaded train loader into memory\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/362/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/354/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a2.ogg /home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a8.ogghas no speech segments, using full waveform\n",
      " has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/592/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1374/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1434/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/659/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/385/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/537/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/511/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1363/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1530/a2.ogg has no speech segments, using full waveform\n",
      "Loaded validation loader into memory\n"
     ]
    }
   ],
   "source": [
    "train_loader = MemoryLoadedDataLoader(train_loader, device=device)\n",
    "print(\"Loaded train loader into memory\")\n",
    "val_loader = MemoryLoadedDataLoader(val_loader, device=device)\n",
    "print(\"Loaded validation loader into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91ba076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.FusionCNN import ContextFusionCNN\n",
    "reload_function(ContextFusionCNN)\n",
    "model = ContextFusionCNN(1,2, num_words=N_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03a3a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:42.755943Z",
     "start_time": "2025-07-29T09:22:19.522018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6862, Train Acc: 0.5641, Val Loss: 0.6831, Val Acc: 0.5623\n",
      "Epoch 2, Train Loss: 0.6818, Train Acc: 0.5740, Val Loss: 0.6773, Val Acc: 0.5637\n",
      "Epoch 3, Train Loss: 0.6775, Train Acc: 0.5764, Val Loss: 0.6711, Val Acc: 0.5737\n",
      "Epoch 4, Train Loss: 0.6719, Train Acc: 0.5745, Val Loss: 0.6636, Val Acc: 0.5807\n",
      "Epoch 5, Train Loss: 0.6689, Train Acc: 0.5943, Val Loss: 0.6575, Val Acc: 0.5992\n",
      "Epoch 6, Train Loss: 0.6649, Train Acc: 0.6080, Val Loss: 0.6494, Val Acc: 0.6643\n",
      "Epoch 7, Train Loss: 0.6595, Train Acc: 0.6090, Val Loss: 0.6431, Val Acc: 0.6969\n",
      "Epoch 8, Train Loss: 0.6576, Train Acc: 0.6232, Val Loss: 0.6373, Val Acc: 0.7082\n",
      "Epoch 9, Train Loss: 0.6567, Train Acc: 0.6161, Val Loss: 0.6288, Val Acc: 0.7096\n",
      "Epoch 10, Train Loss: 0.6467, Train Acc: 0.6217, Val Loss: 0.6221, Val Acc: 0.7096\n",
      "Epoch 11, Train Loss: 0.6444, Train Acc: 0.6378, Val Loss: 0.6154, Val Acc: 0.7181\n",
      "Epoch 12, Train Loss: 0.6387, Train Acc: 0.6421, Val Loss: 0.6101, Val Acc: 0.7167\n",
      "Epoch 13, Train Loss: 0.6377, Train Acc: 0.6567, Val Loss: 0.6043, Val Acc: 0.7167\n",
      "Epoch 14, Train Loss: 0.6331, Train Acc: 0.6548, Val Loss: 0.6005, Val Acc: 0.7210\n",
      "Epoch 15, Train Loss: 0.6266, Train Acc: 0.6572, Val Loss: 0.5948, Val Acc: 0.7167\n",
      "Epoch 16, Train Loss: 0.6249, Train Acc: 0.6657, Val Loss: 0.5921, Val Acc: 0.7224\n",
      "Epoch 17, Train Loss: 0.6176, Train Acc: 0.6723, Val Loss: 0.5849, Val Acc: 0.7295\n",
      "Epoch 18, Train Loss: 0.6204, Train Acc: 0.6652, Val Loss: 0.5834, Val Acc: 0.7337\n",
      "Epoch 19, Train Loss: 0.6073, Train Acc: 0.6766, Val Loss: 0.5768, Val Acc: 0.7337\n",
      "Epoch 20, Train Loss: 0.6118, Train Acc: 0.6690, Val Loss: 0.5796, Val Acc: 0.7295\n",
      "Epoch 21, Train Loss: 0.6127, Train Acc: 0.6719, Val Loss: 0.5790, Val Acc: 0.7309\n",
      "Epoch 22, Train Loss: 0.6110, Train Acc: 0.6671, Val Loss: 0.5770, Val Acc: 0.7323\n",
      "Epoch 23, Train Loss: 0.6075, Train Acc: 0.6865, Val Loss: 0.5773, Val Acc: 0.7280\n",
      "Epoch 24, Train Loss: 0.5961, Train Acc: 0.6785, Val Loss: 0.5733, Val Acc: 0.7280\n",
      "Epoch 25, Train Loss: 0.6153, Train Acc: 0.6709, Val Loss: 0.5736, Val Acc: 0.7280\n",
      "Epoch 26, Train Loss: 0.6012, Train Acc: 0.6936, Val Loss: 0.5719, Val Acc: 0.7252\n",
      "Epoch 27, Train Loss: 0.6022, Train Acc: 0.6946, Val Loss: 0.5700, Val Acc: 0.7309\n",
      "Epoch 28, Train Loss: 0.6005, Train Acc: 0.6827, Val Loss: 0.5715, Val Acc: 0.7280\n",
      "Epoch 29, Train Loss: 0.6013, Train Acc: 0.6747, Val Loss: 0.5672, Val Acc: 0.7436\n",
      "Epoch 30, Train Loss: 0.5962, Train Acc: 0.6941, Val Loss: 0.5698, Val Acc: 0.7323\n",
      "Epoch 31, Train Loss: 0.6036, Train Acc: 0.6950, Val Loss: 0.5684, Val Acc: 0.7210\n",
      "Epoch 32, Train Loss: 0.5890, Train Acc: 0.6988, Val Loss: 0.5636, Val Acc: 0.7224\n",
      "Epoch 33, Train Loss: 0.5891, Train Acc: 0.6922, Val Loss: 0.5626, Val Acc: 0.7266\n",
      "Epoch 34, Train Loss: 0.5968, Train Acc: 0.7026, Val Loss: 0.5640, Val Acc: 0.7295\n",
      "Epoch 35, Train Loss: 0.5902, Train Acc: 0.6993, Val Loss: 0.5649, Val Acc: 0.7210\n",
      "Epoch 36, Train Loss: 0.5892, Train Acc: 0.7017, Val Loss: 0.5625, Val Acc: 0.7224\n",
      "Epoch 37, Train Loss: 0.5967, Train Acc: 0.6950, Val Loss: 0.5653, Val Acc: 0.7323\n",
      "Epoch 38, Train Loss: 0.5922, Train Acc: 0.6941, Val Loss: 0.5622, Val Acc: 0.7394\n",
      "Epoch 39, Train Loss: 0.5909, Train Acc: 0.7017, Val Loss: 0.5613, Val Acc: 0.7337\n",
      "Epoch 40, Train Loss: 0.5872, Train Acc: 0.6969, Val Loss: 0.5586, Val Acc: 0.7351\n",
      "Epoch 41, Train Loss: 0.5936, Train Acc: 0.6922, Val Loss: 0.5607, Val Acc: 0.7380\n",
      "Epoch 42, Train Loss: 0.5854, Train Acc: 0.6983, Val Loss: 0.5609, Val Acc: 0.7394\n",
      "Epoch 43, Train Loss: 0.5905, Train Acc: 0.7064, Val Loss: 0.5618, Val Acc: 0.7351\n",
      "Epoch 44, Train Loss: 0.5841, Train Acc: 0.7035, Val Loss: 0.5592, Val Acc: 0.7295\n",
      "Epoch 45, Train Loss: 0.5872, Train Acc: 0.7045, Val Loss: 0.5572, Val Acc: 0.7351\n",
      "Epoch 46, Train Loss: 0.5845, Train Acc: 0.7102, Val Loss: 0.5569, Val Acc: 0.7394\n",
      "Epoch 47, Train Loss: 0.5887, Train Acc: 0.6927, Val Loss: 0.5574, Val Acc: 0.7394\n",
      "Epoch 48, Train Loss: 0.5799, Train Acc: 0.7078, Val Loss: 0.5593, Val Acc: 0.7309\n",
      "Epoch 49, Train Loss: 0.5778, Train Acc: 0.7116, Val Loss: 0.5516, Val Acc: 0.7323\n",
      "Epoch 50, Train Loss: 0.5744, Train Acc: 0.7111, Val Loss: 0.5507, Val Acc: 0.7280\n",
      "Epoch 51, Train Loss: 0.5805, Train Acc: 0.6931, Val Loss: 0.5506, Val Acc: 0.7408\n",
      "Epoch 52, Train Loss: 0.5804, Train Acc: 0.7087, Val Loss: 0.5495, Val Acc: 0.7394\n",
      "Epoch 53, Train Loss: 0.5750, Train Acc: 0.7177, Val Loss: 0.5505, Val Acc: 0.7422\n",
      "Epoch 54, Train Loss: 0.5791, Train Acc: 0.7130, Val Loss: 0.5492, Val Acc: 0.7422\n",
      "Epoch 55, Train Loss: 0.5791, Train Acc: 0.6969, Val Loss: 0.5477, Val Acc: 0.7394\n",
      "Epoch 56, Train Loss: 0.5789, Train Acc: 0.7106, Val Loss: 0.5515, Val Acc: 0.7408\n",
      "Epoch 57, Train Loss: 0.5680, Train Acc: 0.7248, Val Loss: 0.5496, Val Acc: 0.7394\n",
      "Epoch 58, Train Loss: 0.5676, Train Acc: 0.7220, Val Loss: 0.5467, Val Acc: 0.7408\n",
      "Epoch 59, Train Loss: 0.5776, Train Acc: 0.7087, Val Loss: 0.5465, Val Acc: 0.7408\n",
      "Epoch 60, Train Loss: 0.5689, Train Acc: 0.7243, Val Loss: 0.5425, Val Acc: 0.7394\n",
      "Epoch 61, Train Loss: 0.5739, Train Acc: 0.7168, Val Loss: 0.5458, Val Acc: 0.7365\n",
      "Epoch 62, Train Loss: 0.5640, Train Acc: 0.7225, Val Loss: 0.5491, Val Acc: 0.7394\n",
      "Epoch 63, Train Loss: 0.5726, Train Acc: 0.7135, Val Loss: 0.5424, Val Acc: 0.7408\n",
      "Epoch 64, Train Loss: 0.5688, Train Acc: 0.7215, Val Loss: 0.5406, Val Acc: 0.7408\n",
      "Epoch 65, Train Loss: 0.5706, Train Acc: 0.7149, Val Loss: 0.5430, Val Acc: 0.7365\n",
      "Epoch 66, Train Loss: 0.5661, Train Acc: 0.7225, Val Loss: 0.5412, Val Acc: 0.7323\n",
      "Epoch 67, Train Loss: 0.5648, Train Acc: 0.7291, Val Loss: 0.5443, Val Acc: 0.7337\n",
      "Epoch 68, Train Loss: 0.5658, Train Acc: 0.7305, Val Loss: 0.5387, Val Acc: 0.7380\n",
      "Epoch 69, Train Loss: 0.5688, Train Acc: 0.7210, Val Loss: 0.5434, Val Acc: 0.7408\n",
      "Epoch 70, Train Loss: 0.5518, Train Acc: 0.7310, Val Loss: 0.5414, Val Acc: 0.7380\n",
      "Epoch 71, Train Loss: 0.5605, Train Acc: 0.7314, Val Loss: 0.5398, Val Acc: 0.7450\n",
      "Epoch 72, Train Loss: 0.5526, Train Acc: 0.7357, Val Loss: 0.5325, Val Acc: 0.7394\n",
      "Epoch 73, Train Loss: 0.5583, Train Acc: 0.7215, Val Loss: 0.5381, Val Acc: 0.7365\n",
      "Epoch 74, Train Loss: 0.5586, Train Acc: 0.7362, Val Loss: 0.5345, Val Acc: 0.7380\n",
      "Epoch 75, Train Loss: 0.5591, Train Acc: 0.7262, Val Loss: 0.5365, Val Acc: 0.7394\n",
      "Epoch 76, Train Loss: 0.5577, Train Acc: 0.7348, Val Loss: 0.5326, Val Acc: 0.7394\n",
      "Epoch 77, Train Loss: 0.5665, Train Acc: 0.7314, Val Loss: 0.5356, Val Acc: 0.7436\n",
      "Epoch 78, Train Loss: 0.5512, Train Acc: 0.7366, Val Loss: 0.5322, Val Acc: 0.7380\n",
      "Epoch 79, Train Loss: 0.5618, Train Acc: 0.7281, Val Loss: 0.5329, Val Acc: 0.7394\n",
      "Epoch 80, Train Loss: 0.5553, Train Acc: 0.7291, Val Loss: 0.5326, Val Acc: 0.7380\n",
      "Epoch 81, Train Loss: 0.5434, Train Acc: 0.7310, Val Loss: 0.5280, Val Acc: 0.7380\n",
      "Epoch 82, Train Loss: 0.5523, Train Acc: 0.7371, Val Loss: 0.5301, Val Acc: 0.7351\n",
      "Epoch 83, Train Loss: 0.5479, Train Acc: 0.7385, Val Loss: 0.5293, Val Acc: 0.7380\n",
      "Epoch 84, Train Loss: 0.5578, Train Acc: 0.7343, Val Loss: 0.5287, Val Acc: 0.7394\n",
      "Epoch 85, Train Loss: 0.5387, Train Acc: 0.7409, Val Loss: 0.5259, Val Acc: 0.7450\n",
      "Epoch 86, Train Loss: 0.5461, Train Acc: 0.7366, Val Loss: 0.5262, Val Acc: 0.7408\n",
      "Epoch 87, Train Loss: 0.5383, Train Acc: 0.7452, Val Loss: 0.5229, Val Acc: 0.7436\n",
      "Epoch 88, Train Loss: 0.5408, Train Acc: 0.7376, Val Loss: 0.5262, Val Acc: 0.7408\n",
      "Epoch 89, Train Loss: 0.5563, Train Acc: 0.7281, Val Loss: 0.5267, Val Acc: 0.7365\n",
      "Epoch 90, Train Loss: 0.5489, Train Acc: 0.7267, Val Loss: 0.5249, Val Acc: 0.7323\n",
      "Epoch 91, Train Loss: 0.5380, Train Acc: 0.7442, Val Loss: 0.5227, Val Acc: 0.7422\n",
      "Epoch 92, Train Loss: 0.5495, Train Acc: 0.7291, Val Loss: 0.5260, Val Acc: 0.7323\n",
      "Epoch 93, Train Loss: 0.5454, Train Acc: 0.7485, Val Loss: 0.5245, Val Acc: 0.7380\n",
      "Epoch 94, Train Loss: 0.5359, Train Acc: 0.7248, Val Loss: 0.5220, Val Acc: 0.7380\n",
      "Epoch 95, Train Loss: 0.5330, Train Acc: 0.7395, Val Loss: 0.5217, Val Acc: 0.7465\n",
      "Epoch 96, Train Loss: 0.5297, Train Acc: 0.7541, Val Loss: 0.5208, Val Acc: 0.7380\n",
      "Epoch 97, Train Loss: 0.5280, Train Acc: 0.7433, Val Loss: 0.5195, Val Acc: 0.7380\n",
      "Epoch 98, Train Loss: 0.5278, Train Acc: 0.7456, Val Loss: 0.5166, Val Acc: 0.7408\n",
      "Epoch 99, Train Loss: 0.5297, Train Acc: 0.7527, Val Loss: 0.5181, Val Acc: 0.7450\n",
      "Epoch 100, Train Loss: 0.5411, Train Acc: 0.7395, Val Loss: 0.5148, Val Acc: 0.7408\n",
      "Epoch 101, Train Loss: 0.5365, Train Acc: 0.7494, Val Loss: 0.5171, Val Acc: 0.7436\n",
      "Epoch 102, Train Loss: 0.5475, Train Acc: 0.7433, Val Loss: 0.5207, Val Acc: 0.7351\n",
      "Epoch 103, Train Loss: 0.5104, Train Acc: 0.7589, Val Loss: 0.5218, Val Acc: 0.7323\n",
      "Epoch 104, Train Loss: 0.5260, Train Acc: 0.7475, Val Loss: 0.5141, Val Acc: 0.7479\n",
      "Epoch 105, Train Loss: 0.5266, Train Acc: 0.7475, Val Loss: 0.5152, Val Acc: 0.7436\n",
      "Epoch 106, Train Loss: 0.5272, Train Acc: 0.7617, Val Loss: 0.5182, Val Acc: 0.7394\n",
      "Epoch 107, Train Loss: 0.5246, Train Acc: 0.7508, Val Loss: 0.5161, Val Acc: 0.7351\n",
      "Epoch 108, Train Loss: 0.5152, Train Acc: 0.7598, Val Loss: 0.5085, Val Acc: 0.7479\n",
      "Epoch 109, Train Loss: 0.5221, Train Acc: 0.7518, Val Loss: 0.5111, Val Acc: 0.7436\n",
      "Epoch 110, Train Loss: 0.5250, Train Acc: 0.7537, Val Loss: 0.5103, Val Acc: 0.7450\n",
      "Epoch 111, Train Loss: 0.5128, Train Acc: 0.7560, Val Loss: 0.5105, Val Acc: 0.7422\n",
      "Epoch 112, Train Loss: 0.5136, Train Acc: 0.7678, Val Loss: 0.5137, Val Acc: 0.7394\n",
      "Epoch 113, Train Loss: 0.5109, Train Acc: 0.7622, Val Loss: 0.5112, Val Acc: 0.7479\n",
      "Epoch 114, Train Loss: 0.5244, Train Acc: 0.7442, Val Loss: 0.5131, Val Acc: 0.7394\n",
      "Epoch 115, Train Loss: 0.5089, Train Acc: 0.7664, Val Loss: 0.5102, Val Acc: 0.7436\n",
      "Epoch 116, Train Loss: 0.5084, Train Acc: 0.7664, Val Loss: 0.5060, Val Acc: 0.7465\n",
      "Epoch 117, Train Loss: 0.5074, Train Acc: 0.7707, Val Loss: 0.5060, Val Acc: 0.7521\n",
      "Epoch 118, Train Loss: 0.5099, Train Acc: 0.7645, Val Loss: 0.5087, Val Acc: 0.7465\n",
      "Epoch 119, Train Loss: 0.4985, Train Acc: 0.7712, Val Loss: 0.5092, Val Acc: 0.7521\n",
      "Epoch 120, Train Loss: 0.5008, Train Acc: 0.7655, Val Loss: 0.5028, Val Acc: 0.7465\n",
      "Epoch 121, Train Loss: 0.4945, Train Acc: 0.7730, Val Loss: 0.5043, Val Acc: 0.7493\n",
      "Epoch 122, Train Loss: 0.5102, Train Acc: 0.7556, Val Loss: 0.5066, Val Acc: 0.7507\n",
      "Epoch 123, Train Loss: 0.5049, Train Acc: 0.7688, Val Loss: 0.5044, Val Acc: 0.7550\n",
      "Epoch 124, Train Loss: 0.5002, Train Acc: 0.7745, Val Loss: 0.5076, Val Acc: 0.7479\n",
      "Epoch 125, Train Loss: 0.4978, Train Acc: 0.7716, Val Loss: 0.5026, Val Acc: 0.7550\n",
      "Epoch 126, Train Loss: 0.4884, Train Acc: 0.7655, Val Loss: 0.5022, Val Acc: 0.7507\n",
      "Epoch 127, Train Loss: 0.5059, Train Acc: 0.7660, Val Loss: 0.5050, Val Acc: 0.7493\n",
      "Epoch 128, Train Loss: 0.4993, Train Acc: 0.7712, Val Loss: 0.5040, Val Acc: 0.7535\n",
      "Epoch 129, Train Loss: 0.4900, Train Acc: 0.7712, Val Loss: 0.5007, Val Acc: 0.7550\n",
      "Epoch 130, Train Loss: 0.4876, Train Acc: 0.7783, Val Loss: 0.5021, Val Acc: 0.7507\n",
      "Epoch 131, Train Loss: 0.4818, Train Acc: 0.7773, Val Loss: 0.5022, Val Acc: 0.7493\n",
      "Epoch 132, Train Loss: 0.5047, Train Acc: 0.7570, Val Loss: 0.5008, Val Acc: 0.7507\n",
      "Epoch 133, Train Loss: 0.4857, Train Acc: 0.7730, Val Loss: 0.4993, Val Acc: 0.7493\n",
      "Epoch 134, Train Loss: 0.4837, Train Acc: 0.7816, Val Loss: 0.4989, Val Acc: 0.7493\n",
      "Epoch 135, Train Loss: 0.4903, Train Acc: 0.7787, Val Loss: 0.4978, Val Acc: 0.7493\n",
      "Epoch 136, Train Loss: 0.4903, Train Acc: 0.7712, Val Loss: 0.4973, Val Acc: 0.7479\n",
      "Epoch 137, Train Loss: 0.4851, Train Acc: 0.7707, Val Loss: 0.4975, Val Acc: 0.7550\n",
      "Epoch 138, Train Loss: 0.4862, Train Acc: 0.7801, Val Loss: 0.4996, Val Acc: 0.7535\n",
      "Epoch 139, Train Loss: 0.4872, Train Acc: 0.7768, Val Loss: 0.4982, Val Acc: 0.7465\n",
      "Epoch 140, Train Loss: 0.4709, Train Acc: 0.7844, Val Loss: 0.4988, Val Acc: 0.7436\n"
     ]
    }
   ],
   "source": [
    "# Model variables definition.\n",
    "pth = \"ContextFusionCNN.pth\"\n",
    "lr = 1e-4  # Reduce from 1e-3\n",
    "epochs = 140\n",
    "model = model.to(device)\n",
    "reload_function(train)\n",
    "reload_function(evaluate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)  # Add L2 regularization\n",
    "\n",
    "# Add learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Saving the model locally\n",
    "torch.save(model.state_dict(), os.path.join(RESULT_DIRECTORY, pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397fcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/620/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/489/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/592/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1349/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/456/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1093/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1024/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/765/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1544/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1300/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/744/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/500/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/706/a5.ogg has no speech segments, using full waveform\n",
      "Loaded test loader into memory\n"
     ]
    }
   ],
   "source": [
    "test_loader = MemoryLoadedDataLoader(test_loader, device=device)\n",
    "print(\"Loaded test loader into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FINAL TEST RESULTS\n",
      "Test Loss: 0.5561\n",
      "Test Accuracy: 0.7195\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"FINAL TEST RESULTS\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mandarin_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
