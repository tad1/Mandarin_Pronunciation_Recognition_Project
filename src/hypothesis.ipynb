{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f8129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:06:49.748097Z",
     "start_time": "2025-07-29T09:06:49.733744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from polars import DataFrame\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple\n",
    "import wandb\n",
    "\n",
    "from path import RESULT_DIRECTORY\n",
    "from develop import reload_function, reload_module\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57adc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.391376Z",
     "start_time": "2025-07-29T09:04:37.356941Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.source.pg_experiment import get_pg_experiment_dataframe\n",
    "\n",
    "df_pronv1, _ = get_pg_experiment_dataframe(\".ogg\", assesment_version=\"v1\")\n",
    "df_pronv2, _ = get_pg_experiment_dataframe(\".ogg\", assesment_version=\"v2\")\n",
    "\n",
    "dataframe = df_pronv1.join(df_pronv2, on=[\"id_student\", \"word_id\"], how=\"inner\", suffix=\"_v2\")\n",
    "dataframe = dataframe.rename({\"value\": \"v1_value\", \"value_v2\": \"v2_value\"})\n",
    "dataframe = dataframe.with_columns(word_id = pl.struct(\"word_id\").rank(\"dense\"))\n",
    "dataframe = dataframe.filter(pl.col(\"stage\") == 1)\n",
    "\n",
    "df_outer = dataframe.filter(pl.col(\"v1_value\") != pl.col(\"v2_value\"))\n",
    "df_inner = dataframe.filter(pl.col(\"v1_value\") == pl.col(\"v2_value\"))\n",
    "\n",
    "\n",
    "\n",
    "N_WORDS = dataframe.select(pl.col(\"word_id\").n_unique()).to_numpy()[0][0]\n",
    "print(f\"Number of unique words: {N_WORDS}\")\n",
    "print(f\"Number of samples: {dataframe.shape[0]}\")\n",
    "print(f\"Samples with v1_value != v2_value: {df_outer.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95dcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.442136Z",
     "start_time": "2025-07-29T09:04:37.416770Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(df_outer: pl.DataFrame, df_inner: pl.DataFrame, label_col: str, train_frac=0.8, val_frac=0.1, seed=42) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    classes = df_outer.select(label_col).unique().to_series()\n",
    "    train_rows, val_rows, test_rows = [], [], []\n",
    "    rng = np.random.RandomState(seed)\n",
    "    df_sum = pl.concat([df_outer, df_inner])\n",
    "    \n",
    "    n_subset = df_inner.height\n",
    "    n_test = int((1 - train_frac - val_frac) * df_sum.height)\n",
    "    indices_subset = rng.permutation(n_subset)\n",
    "    test_rows.append(df_inner[indices_subset[:n_test]])\n",
    "    \n",
    "    df = pl.concat([df_outer, df_inner[indices_subset[n_test:]]])\n",
    "    \n",
    "    # update fractions\n",
    "    total_frac = train_frac + val_frac\n",
    "    train_frac = train_frac / total_frac\n",
    "    val_frac = val_frac / total_frac\n",
    "\n",
    "\n",
    "    for cls in classes:\n",
    "        class_df = df.filter(pl.col(label_col) == cls)\n",
    "        n = class_df.height\n",
    "        indices = rng.permutation(n)\n",
    "\n",
    "        train_end = int(train_frac * n)\n",
    "        val_end = int((train_frac + val_frac) * n)\n",
    "\n",
    "        train_rows.append(class_df[indices[:train_end]])\n",
    "        val_rows.append(class_df[indices[train_end:val_end]])\n",
    "\n",
    "    train_df = pl.concat(train_rows)\n",
    "    val_df = pl.concat(val_rows)\n",
    "    test_df = pl.concat(test_rows)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd331ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.500687Z",
     "start_time": "2025-07-29T09:04:37.486859Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import Cast, TorchDataset\n",
    "from pytorch_dataloader import build_collate_fn, PaddingCollate, DefaultCollate\n",
    "from transformation import Channels, RMSEnergy, TorchVadMFCC, ZeroCrossingRate\n",
    "\n",
    "TRAIN_SPLIT = 0.6\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT - VAL_SPLIT\n",
    "train_pl, val_pl, test_pl = split(df_outer=df_outer, df_inner=df_inner, label_col=\"word_id\", train_frac=TRAIN_SPLIT, val_frac=VAL_SPLIT)\n",
    "val_pl = val_pl.filter(pl.col(\"v1_value\") == pl.col(\"v2_value\"))\n",
    "test_pl = test_pl.filter(pl.col(\"v1_value\") == pl.col(\"v2_value\"))\n",
    "\n",
    "def to_dataset(dataframe: DataFrame) -> TorchDataset:\n",
    "    return TorchDataset(\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"stack\",\"multiply\")(\n",
    "            TorchVadMFCC(delta=0),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"cat\",\"multiply\")(\n",
    "            ZeroCrossingRate(),\n",
    "            RMSEnergy(),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"word_id\"), lambda x: torch.tensor(x-1, dtype=torch.long)),\n",
    "    Cast(dataframe.get_column(\"v1_value\"), lambda x: torch.tensor(x).float()),\n",
    "    Cast(dataframe.get_column(\"v2_value\"), lambda x: torch.tensor(x).float()),\n",
    ")\n",
    "\n",
    "collate_fn = build_collate_fn(\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=80, pad_dim=2),\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=80, pad_dim=1),\n",
    "    DefaultCollate(),\n",
    "    DefaultCollate(),\n",
    "    DefaultCollate(),\n",
    ")\n",
    "dataset_train = to_dataset(train_pl)\n",
    "dataset_val = to_dataset(val_pl)\n",
    "dataset_test = to_dataset(test_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be889768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#note, if you are using Windows you MUST set `num_workers=0` - TL;DT multithreading DON'T work in notebooks because Windows DON'T have `fork()`\n",
    "num_workers = 0 if name == \"nt\" else 4\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "for x in next(iter(train_loader)):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf890d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:05:23.032498Z",
     "start_time": "2025-07-29T09:04:37.522932Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_dataloader import MemoryLoadedDataLoader\n",
    "train_loader = MemoryLoadedDataLoader(train_loader, device=device)\n",
    "print(\"Loaded train loader into memory\")\n",
    "val_loader = MemoryLoadedDataLoader(val_loader, device=device)\n",
    "print(\"Loaded validation loader into memory\")\n",
    "test_loader = MemoryLoadedDataLoader(test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ba076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.FusionCNN import ContextFusionCNN, ContextCNN\n",
    "from models.Guesser import ContextGuesser\n",
    "\n",
    "cfcnn_model = ContextFusionCNN(n_2d_channels=1, n_1d_channels=2, num_words=N_WORDS)\n",
    "ccnn_model = ContextCNN(n_2d_channels=1, num_words=N_WORDS)\n",
    "guesser_model = ContextGuesser(num_words=N_WORDS)\n",
    "models = [guesser_model, cfcnn_model, ccnn_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe7b02",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a3a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:42.755943Z",
     "start_time": "2025-07-29T09:22:19.522018Z"
    }
   },
   "outputs": [],
   "source": [
    "from type_helpers import Kwargs\n",
    "\n",
    "epochs = 140\n",
    "\n",
    "Optimizer = torch.optim.Adam\n",
    "OptimizerKwargs = Kwargs(Optimizer)\n",
    "optimizer_config = OptimizerKwargs(\n",
    "    lr=1e-4,\n",
    "    weight_decay= 1e-4,\n",
    ")\n",
    "\n",
    "Scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "SchedulerKwargs = Kwargs(Scheduler)\n",
    "\n",
    "scheduler_config = SchedulerKwargs(\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5\n",
    ")\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SimpleCNN_v2 import train, evaluate\n",
    "\n",
    "def train_model(model):\n",
    "    model = model.to(device)\n",
    "    optimizer = Optimizer(model.parameters(), **optimizer_config)\n",
    "    scheduler = Scheduler(optimizer, **scheduler_config)\n",
    "\n",
    "    run = wandb.init(\n",
    "        # name of the run\n",
    "        name=f\"14+11 experiment - {model.__class__.__name__}\",\n",
    "        config={\n",
    "            \"Name\": f\"{model.__class__.__name__}\",\n",
    "            \"learning_rate\": optimizer_config[\"lr\"],\n",
    "            \"optimizer\": f\"{Optimizer.__name__}\",\n",
    "            \"criterion\": f\"{criterion.__class__.__name__}\",\n",
    "            \"architecture\": f\"{model.__class__.__name__}\",\n",
    "            \"architecture_details\": str(model),\n",
    "            \"dataset\": \"Stage-I\",\n",
    "            \"train_val_test(%)\": f'{TRAIN_SPLIT}-{VAL_SPLIT}-{TEST_SPLIT}',\n",
    "            \"epochs\": epochs,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for label_version in [\"v1\",\"v2\"]:\n",
    "            train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, label_version=label_version, interleave_labels=True)\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device, label_version=label_version, interleave_labels=True)\n",
    "            scheduler.step(val_loss)\n",
    "        run.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, })\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    run.log({\"model_eval\": model.eval()})\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    run.log({\"test_acc\": test_acc, \"test_loss\": test_loss})\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    # Saving the model to pth and adding it to the artifacts of the run, there is 5GB of memory on wandb, so we should be fine.\n",
    "    torch.save(model.state_dict(), os.path.join(RESULT_DIRECTORY, f\"{model.__class__.__name__}.pth\"))\n",
    "    artifact = wandb.Artifact(f\"{model.__class__.__name__}-model\", type=\"model\")\n",
    "    artifact.add_file(os.path.join(RESULT_DIRECTORY, f\"{model.__class__.__name__}.pth\"))\n",
    "    run.log_artifact(artifact)\n",
    "\n",
    "    # Finish the run so it gets sent to the remote. You can discover the run right after that on the dashboard.\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mandarin_Pronunciation_Recognition_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
