{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12f8129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:06:49.748097Z",
     "start_time": "2025-07-29T09:06:49.733744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data.source.pg_experiment import get_pg_experiment_dataframe\n",
    "import polars as pl\n",
    "\n",
    "from models.SimplifiedLightweightCNN import SimplifiedLightweightCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport models.SimplifiedLightweightCNN\n",
    "from models.SimpleCNN_v2 import train, evaluate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from path import RESULT_DIRECTORY\n",
    "import wandb\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57adc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.391376Z",
     "start_time": "2025-07-29T09:04:37.356941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_pg_experiment_dataset(): WARNING, Dropped 2 rows with missing files\n",
      "get_pg_experiment_dataset(): WARNING, Dropped 2 rows with missing files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<sys>:0: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "<sys>:0: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (518, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id_student</th><th>value</th><th>word_id</th><th>rec_path</th><th>stage</th><th>univ</th><th>gender</th><th>mother</th></tr><tr><td>i64</td><td>i64</td><td>u32</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>8</td><td>0</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;PG_CS_MA_1&quot;</td><td>&quot;m&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>9</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;PG_CS_MA_1&quot;</td><td>&quot;f&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>10</td><td>0</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;PG_CS_MA_1&quot;</td><td>&quot;m&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>11</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;PG_CS_MA_1&quot;</td><td>&quot;f&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>21</td><td>0</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;PG_CS_MA_1&quot;</td><td>&quot;f&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1537</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;CLES_UMK5&quot;</td><td>&quot;f&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>1539</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;CLES_UMK5&quot;</td><td>&quot;m&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>1542</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;CLES_UMK5&quot;</td><td>&quot;m&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>1543</td><td>1</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;CLES_UMK5&quot;</td><td>&quot;f&quot;</td><td>&quot;polish&quot;</td></tr><tr><td>1544</td><td>0</td><td>1</td><td>&quot;/home/tad1/Projects/AI/Mandari…</td><td>1</td><td>&quot;CLES_UMK5&quot;</td><td>&quot;m&quot;</td><td>&quot;polish&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (518, 8)\n",
       "┌────────────┬───────┬─────────┬────────────────────────────┬───────┬────────────┬────────┬────────┐\n",
       "│ id_student ┆ value ┆ word_id ┆ rec_path                   ┆ stage ┆ univ       ┆ gender ┆ mother │\n",
       "│ ---        ┆ ---   ┆ ---     ┆ ---                        ┆ ---   ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ i64        ┆ i64   ┆ u32     ┆ str                        ┆ i32   ┆ str        ┆ str    ┆ str    │\n",
       "╞════════════╪═══════╪═════════╪════════════════════════════╪═══════╪════════════╪════════╪════════╡\n",
       "│ 8          ┆ 0     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ PG_CS_MA_1 ┆ m      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 9          ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ PG_CS_MA_1 ┆ f      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 10         ┆ 0     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ PG_CS_MA_1 ┆ m      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 11         ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ PG_CS_MA_1 ┆ f      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 21         ┆ 0     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ PG_CS_MA_1 ┆ f      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ …          ┆ …     ┆ …       ┆ …                          ┆ …     ┆ …          ┆ …      ┆ …      │\n",
       "│ 1537       ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ CLES_UMK5  ┆ f      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 1539       ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ CLES_UMK5  ┆ m      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 1542       ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ CLES_UMK5  ┆ m      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 1543       ┆ 1     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ CLES_UMK5  ┆ f      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "│ 1544       ┆ 0     ┆ 1       ┆ /home/tad1/Projects/AI/Man ┆ 1     ┆ CLES_UMK5  ┆ m      ┆ polish │\n",
       "│            ┆       ┆         ┆ dari…                      ┆       ┆            ┆        ┆        │\n",
       "└────────────┴───────┴─────────┴────────────────────────────┴───────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pron, df_tone = get_pg_experiment_dataframe(\".ogg\")\n",
    "df_stageI_polish = df_pron.with_columns(word_id = pl.struct(\"word_id\").rank(\"dense\"))\n",
    "df_stageI_polish = df_stageI_polish.filter(pl.col(\"word_id\") == 1)\n",
    "df_stageI_polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a95dcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.442136Z",
     "start_time": "2025-07-29T09:04:37.416770Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def stratified_split(df: pl.DataFrame, label_col: str, train_frac=0.8, val_frac=0.1, seed=42) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    classes = df.select(label_col).unique().to_series()\n",
    "    train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    for cls in classes:\n",
    "        class_df = df.filter(pl.col(label_col) == cls)\n",
    "        n = class_df.height\n",
    "        indices = rng.permutation(n)\n",
    "\n",
    "        train_end = int(train_frac * n)\n",
    "        val_end = int((train_frac + val_frac) * n)\n",
    "\n",
    "        train_rows.append(class_df[indices[:train_end]])\n",
    "        val_rows.append(class_df[indices[train_end:val_end]])\n",
    "        test_rows.append(class_df[indices[val_end:]])\n",
    "\n",
    "    train_df = pl.concat(train_rows)\n",
    "    val_df = pl.concat(val_rows)\n",
    "    test_df = pl.concat(test_rows)\n",
    "\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd331ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.500687Z",
     "start_time": "2025-07-29T09:04:37.486859Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import Cast, TorchDataset\n",
    "from develop import reload_function, reload_module\n",
    "import pytorch_dataloader\n",
    "reload_module(pytorch_dataloader)\n",
    "from pytorch_dataloader import ReshapeCollate, build_collate_fn, PaddingCollate, DefaultCollate\n",
    "from functools import partial\n",
    "\n",
    "from transformation import Channels, TorchVadLogMelSpec, TorchVadMFCC\n",
    "\n",
    "reload_function(TorchVadMFCC)\n",
    "\n",
    "TRAIN_SPLIT = 0.6\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT - VAL_SPLIT\n",
    "train_pl, val_pl, test_pl = stratified_split(df_stageI_polish, label_col=\"value\", train_frac=TRAIN_SPLIT, val_frac=VAL_SPLIT)\n",
    "\n",
    "to_dataset = lambda dataframe: TorchDataset(\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"stack\",\"multiply\")(\n",
    "            TorchVadMFCC(delta=0),\n",
    "            TorchVadMFCC(delta=1),\n",
    "            TorchVadMFCC(delta=2),\n",
    "        )), \n",
    "    Cast(dataframe.get_column(\"value\"), lambda x: torch.tensor(x).float()),\n",
    ")\n",
    "\n",
    "collate_fn = build_collate_fn(\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=60, pad_dim=2),\n",
    "    DefaultCollate(),\n",
    ")\n",
    "dataset_train = to_dataset(train_pl)\n",
    "dataset_val = to_dataset(val_pl)\n",
    "dataset_test = to_dataset(test_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be889768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "torch.Size([16, 3, 40, 60]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_dataloader import MemoryLoadedDataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "input, label  = next(iter(train_loader))\n",
    "print(input.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf890d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:05:23.032498Z",
     "start_time": "2025-07-29T09:04:37.522932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a0.ogg\n",
      " has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a0.ogg has no speech segments, using full waveform\n",
      "/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a0.ogg has no speech segments, using full waveform\n",
      "Loaded train loader into memory\n",
      "Loaded validation loader into memory\n"
     ]
    }
   ],
   "source": [
    "train_loader = MemoryLoadedDataLoader(train_loader, device=device)\n",
    "print(\"Loaded train loader into memory\")\n",
    "val_loader = MemoryLoadedDataLoader(val_loader, device=device)\n",
    "print(\"Loaded validation loader into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b6d2264eb25ee64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:22:17.455494Z",
     "start_time": "2025-07-29T09:22:17.447619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=2400, out_features=200, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.8, inplace=False)\n",
       "  (4): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.8, inplace=False)\n",
       "  (7): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (8): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(40* 60, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(200, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4dff728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sequential(\\n  (0): Flatten(start_dim=1, end_dim=-1)\\n  (1): Linear(in_features=2400, out_features=100, bias=True)\\n  (2): ReLU()\\n  (3): Dropout(p=0.7, inplace=False)\\n  (4): Linear(in_features=100, out_features=20, bias=True)\\n  (5): ReLU()\\n  (6): Dropout(p=0.5, inplace=False)\\n  (7): Linear(in_features=20, out_features=1, bias=True)\\n  (8): Sigmoid()\\n)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c91ba076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SimpleCNN_v2 import SimpleCNN\n",
    "reload_function(SimpleCNN)\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a3a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:42.755943Z",
     "start_time": "2025-07-29T09:22:19.522018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hypothesis-5 SimpleCNN</strong> at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/oena0nav' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/oena0nav</a><br> View project at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250808_155229-oena0nav/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tad1/Projects/AI/Mandarin_Pronunciation_Recognition_Project/src/wandb/run-20250808_155324-a1cj9i6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/a1cj9i6x' target=\"_blank\">Hypothesis-5 SimpleCNN</a></strong> to <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/a1cj9i6x' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/a1cj9i6x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6823, Train Acc: 0.5839, Val Loss: 0.6775, Val Acc: 0.5922\n",
      "Epoch 2, Train Loss: 0.6785, Train Acc: 0.5677, Val Loss: 0.6674, Val Acc: 0.5922\n",
      "Epoch 3, Train Loss: 0.6818, Train Acc: 0.5839, Val Loss: 0.6655, Val Acc: 0.5922\n",
      "Epoch 4, Train Loss: 0.6575, Train Acc: 0.5968, Val Loss: 0.6619, Val Acc: 0.5922\n",
      "Epoch 5, Train Loss: 0.6653, Train Acc: 0.5806, Val Loss: 0.6615, Val Acc: 0.6019\n",
      "Epoch 6, Train Loss: 0.6527, Train Acc: 0.6290, Val Loss: 0.6624, Val Acc: 0.6214\n",
      "Epoch 7, Train Loss: 0.6763, Train Acc: 0.6194, Val Loss: 0.6606, Val Acc: 0.6019\n",
      "Epoch 8, Train Loss: 0.6412, Train Acc: 0.6419, Val Loss: 0.6602, Val Acc: 0.6311\n",
      "Epoch 9, Train Loss: 0.6523, Train Acc: 0.6097, Val Loss: 0.6565, Val Acc: 0.6408\n",
      "Epoch 10, Train Loss: 0.6365, Train Acc: 0.6355, Val Loss: 0.6524, Val Acc: 0.6117\n",
      "Epoch 11, Train Loss: 0.6404, Train Acc: 0.6355, Val Loss: 0.6571, Val Acc: 0.6214\n",
      "Epoch 12, Train Loss: 0.6234, Train Acc: 0.6387, Val Loss: 0.6494, Val Acc: 0.6505\n",
      "Epoch 13, Train Loss: 0.6379, Train Acc: 0.6419, Val Loss: 0.6495, Val Acc: 0.6311\n",
      "Epoch 14, Train Loss: 0.6141, Train Acc: 0.6839, Val Loss: 0.6498, Val Acc: 0.6408\n",
      "Epoch 15, Train Loss: 0.6229, Train Acc: 0.6258, Val Loss: 0.6430, Val Acc: 0.6505\n",
      "Epoch 16, Train Loss: 0.6209, Train Acc: 0.6871, Val Loss: 0.6421, Val Acc: 0.6505\n",
      "Epoch 17, Train Loss: 0.6000, Train Acc: 0.6806, Val Loss: 0.6448, Val Acc: 0.6408\n",
      "Epoch 18, Train Loss: 0.6123, Train Acc: 0.6581, Val Loss: 0.6424, Val Acc: 0.6311\n",
      "Epoch 19, Train Loss: 0.6098, Train Acc: 0.6677, Val Loss: 0.6386, Val Acc: 0.6505\n",
      "Epoch 20, Train Loss: 0.6078, Train Acc: 0.6677, Val Loss: 0.6468, Val Acc: 0.6408\n",
      "Epoch 21, Train Loss: 0.5946, Train Acc: 0.6742, Val Loss: 0.6431, Val Acc: 0.6408\n",
      "Epoch 22, Train Loss: 0.6080, Train Acc: 0.6677, Val Loss: 0.6396, Val Acc: 0.6408\n",
      "Epoch 23, Train Loss: 0.5747, Train Acc: 0.7000, Val Loss: 0.6424, Val Acc: 0.6311\n",
      "Epoch 24, Train Loss: 0.5459, Train Acc: 0.7419, Val Loss: 0.6448, Val Acc: 0.6214\n",
      "Epoch 25, Train Loss: 0.5484, Train Acc: 0.7161, Val Loss: 0.6293, Val Acc: 0.6602\n",
      "Epoch 26, Train Loss: 0.5539, Train Acc: 0.6903, Val Loss: 0.6506, Val Acc: 0.6311\n",
      "Epoch 27, Train Loss: 0.5599, Train Acc: 0.6968, Val Loss: 0.6497, Val Acc: 0.6408\n",
      "Epoch 28, Train Loss: 0.5671, Train Acc: 0.6839, Val Loss: 0.6267, Val Acc: 0.6602\n",
      "Epoch 29, Train Loss: 0.5367, Train Acc: 0.7355, Val Loss: 0.6383, Val Acc: 0.6602\n",
      "Epoch 30, Train Loss: 0.5330, Train Acc: 0.7516, Val Loss: 0.6278, Val Acc: 0.6699\n",
      "Epoch 31, Train Loss: 0.5504, Train Acc: 0.7032, Val Loss: 0.6410, Val Acc: 0.6408\n",
      "Epoch 32, Train Loss: 0.5168, Train Acc: 0.7387, Val Loss: 0.6461, Val Acc: 0.6505\n",
      "Epoch 33, Train Loss: 0.5078, Train Acc: 0.7452, Val Loss: 0.6290, Val Acc: 0.6408\n",
      "Epoch 34, Train Loss: 0.4647, Train Acc: 0.8226, Val Loss: 0.6353, Val Acc: 0.6699\n",
      "Epoch 35, Train Loss: 0.4883, Train Acc: 0.7710, Val Loss: 0.6417, Val Acc: 0.6602\n",
      "Epoch 36, Train Loss: 0.4827, Train Acc: 0.7774, Val Loss: 0.6356, Val Acc: 0.6699\n",
      "Epoch 37, Train Loss: 0.4743, Train Acc: 0.7839, Val Loss: 0.6418, Val Acc: 0.6602\n",
      "Epoch 38, Train Loss: 0.4913, Train Acc: 0.7710, Val Loss: 0.6432, Val Acc: 0.6796\n",
      "Epoch 39, Train Loss: 0.4592, Train Acc: 0.7935, Val Loss: 0.6389, Val Acc: 0.6796\n",
      "Epoch 40, Train Loss: 0.4450, Train Acc: 0.7935, Val Loss: 0.6410, Val Acc: 0.6602\n",
      "Epoch 41, Train Loss: 0.4510, Train Acc: 0.8097, Val Loss: 0.6480, Val Acc: 0.6602\n",
      "Epoch 42, Train Loss: 0.4267, Train Acc: 0.8226, Val Loss: 0.6489, Val Acc: 0.6699\n",
      "Epoch 43, Train Loss: 0.4722, Train Acc: 0.7968, Val Loss: 0.6486, Val Acc: 0.6602\n",
      "Epoch 44, Train Loss: 0.4558, Train Acc: 0.7935, Val Loss: 0.6439, Val Acc: 0.6796\n",
      "Epoch 45, Train Loss: 0.4452, Train Acc: 0.7871, Val Loss: 0.6394, Val Acc: 0.6699\n",
      "Epoch 46, Train Loss: 0.4553, Train Acc: 0.7839, Val Loss: 0.6573, Val Acc: 0.6602\n",
      "Epoch 47, Train Loss: 0.4430, Train Acc: 0.8000, Val Loss: 0.6466, Val Acc: 0.6796\n",
      "Epoch 48, Train Loss: 0.4440, Train Acc: 0.8065, Val Loss: 0.6390, Val Acc: 0.6602\n",
      "Epoch 49, Train Loss: 0.4265, Train Acc: 0.8226, Val Loss: 0.6560, Val Acc: 0.6699\n",
      "Epoch 50, Train Loss: 0.4439, Train Acc: 0.8097, Val Loss: 0.6512, Val Acc: 0.6796\n",
      "Epoch 51, Train Loss: 0.4573, Train Acc: 0.8000, Val Loss: 0.6519, Val Acc: 0.6796\n",
      "Epoch 52, Train Loss: 0.4333, Train Acc: 0.8161, Val Loss: 0.6514, Val Acc: 0.6796\n",
      "Epoch 53, Train Loss: 0.4235, Train Acc: 0.8161, Val Loss: 0.6470, Val Acc: 0.6602\n",
      "Epoch 54, Train Loss: 0.4352, Train Acc: 0.8065, Val Loss: 0.6497, Val Acc: 0.6699\n",
      "Epoch 55, Train Loss: 0.4528, Train Acc: 0.8129, Val Loss: 0.6478, Val Acc: 0.6602\n",
      "Epoch 56, Train Loss: 0.4508, Train Acc: 0.8065, Val Loss: 0.6477, Val Acc: 0.6699\n",
      "Epoch 57, Train Loss: 0.4358, Train Acc: 0.8097, Val Loss: 0.6453, Val Acc: 0.6602\n",
      "Epoch 58, Train Loss: 0.4178, Train Acc: 0.8548, Val Loss: 0.6475, Val Acc: 0.6602\n",
      "Epoch 59, Train Loss: 0.4010, Train Acc: 0.8387, Val Loss: 0.6507, Val Acc: 0.6699\n",
      "Epoch 60, Train Loss: 0.4238, Train Acc: 0.8000, Val Loss: 0.6503, Val Acc: 0.6699\n",
      "Epoch 61, Train Loss: 0.4133, Train Acc: 0.8258, Val Loss: 0.6508, Val Acc: 0.6699\n",
      "Epoch 62, Train Loss: 0.4478, Train Acc: 0.7710, Val Loss: 0.6523, Val Acc: 0.6796\n",
      "Epoch 63, Train Loss: 0.4151, Train Acc: 0.8387, Val Loss: 0.6497, Val Acc: 0.6602\n",
      "Epoch 64, Train Loss: 0.4370, Train Acc: 0.8161, Val Loss: 0.6514, Val Acc: 0.6699\n",
      "Epoch 65, Train Loss: 0.4565, Train Acc: 0.7968, Val Loss: 0.6538, Val Acc: 0.6796\n",
      "Epoch 66, Train Loss: 0.4216, Train Acc: 0.8194, Val Loss: 0.6501, Val Acc: 0.6699\n",
      "Epoch 67, Train Loss: 0.4326, Train Acc: 0.8355, Val Loss: 0.6509, Val Acc: 0.6699\n",
      "Epoch 68, Train Loss: 0.4484, Train Acc: 0.8129, Val Loss: 0.6516, Val Acc: 0.6699\n",
      "Epoch 69, Train Loss: 0.4113, Train Acc: 0.8032, Val Loss: 0.6523, Val Acc: 0.6699\n",
      "Epoch 70, Train Loss: 0.4281, Train Acc: 0.8065, Val Loss: 0.6525, Val Acc: 0.6699\n",
      "Epoch 71, Train Loss: 0.4183, Train Acc: 0.8290, Val Loss: 0.6512, Val Acc: 0.6699\n",
      "Epoch 72, Train Loss: 0.4159, Train Acc: 0.8065, Val Loss: 0.6523, Val Acc: 0.6699\n",
      "Epoch 73, Train Loss: 0.4437, Train Acc: 0.7903, Val Loss: 0.6496, Val Acc: 0.6602\n",
      "Epoch 74, Train Loss: 0.4209, Train Acc: 0.8194, Val Loss: 0.6553, Val Acc: 0.6796\n",
      "Epoch 75, Train Loss: 0.4000, Train Acc: 0.8548, Val Loss: 0.6553, Val Acc: 0.6796\n",
      "Epoch 76, Train Loss: 0.4025, Train Acc: 0.8484, Val Loss: 0.6515, Val Acc: 0.6699\n",
      "Epoch 77, Train Loss: 0.4389, Train Acc: 0.8161, Val Loss: 0.6523, Val Acc: 0.6699\n",
      "Epoch 78, Train Loss: 0.3913, Train Acc: 0.8355, Val Loss: 0.6519, Val Acc: 0.6699\n",
      "Epoch 79, Train Loss: 0.4175, Train Acc: 0.8194, Val Loss: 0.6506, Val Acc: 0.6699\n",
      "Epoch 80, Train Loss: 0.4319, Train Acc: 0.8097, Val Loss: 0.6519, Val Acc: 0.6796\n",
      "Epoch 81, Train Loss: 0.4135, Train Acc: 0.8452, Val Loss: 0.6490, Val Acc: 0.6699\n",
      "Epoch 82, Train Loss: 0.4228, Train Acc: 0.8387, Val Loss: 0.6539, Val Acc: 0.6796\n",
      "Epoch 83, Train Loss: 0.4291, Train Acc: 0.8290, Val Loss: 0.6513, Val Acc: 0.6699\n",
      "Epoch 84, Train Loss: 0.4239, Train Acc: 0.8194, Val Loss: 0.6500, Val Acc: 0.6699\n",
      "Epoch 85, Train Loss: 0.4157, Train Acc: 0.8355, Val Loss: 0.6527, Val Acc: 0.6796\n",
      "Epoch 86, Train Loss: 0.4031, Train Acc: 0.8387, Val Loss: 0.6514, Val Acc: 0.6699\n",
      "Epoch 87, Train Loss: 0.4096, Train Acc: 0.8258, Val Loss: 0.6517, Val Acc: 0.6699\n",
      "Epoch 88, Train Loss: 0.4371, Train Acc: 0.8194, Val Loss: 0.6524, Val Acc: 0.6699\n",
      "Epoch 89, Train Loss: 0.4409, Train Acc: 0.8032, Val Loss: 0.6509, Val Acc: 0.6699\n",
      "Epoch 90, Train Loss: 0.4112, Train Acc: 0.8355, Val Loss: 0.6515, Val Acc: 0.6699\n",
      "Epoch 91, Train Loss: 0.4226, Train Acc: 0.8290, Val Loss: 0.6521, Val Acc: 0.6699\n",
      "Epoch 92, Train Loss: 0.4201, Train Acc: 0.8258, Val Loss: 0.6539, Val Acc: 0.6796\n",
      "Epoch 93, Train Loss: 0.4094, Train Acc: 0.8290, Val Loss: 0.6526, Val Acc: 0.6796\n",
      "Epoch 94, Train Loss: 0.4190, Train Acc: 0.8323, Val Loss: 0.6530, Val Acc: 0.6699\n",
      "Epoch 95, Train Loss: 0.4190, Train Acc: 0.7968, Val Loss: 0.6516, Val Acc: 0.6699\n",
      "Epoch 96, Train Loss: 0.4314, Train Acc: 0.8129, Val Loss: 0.6514, Val Acc: 0.6699\n",
      "Epoch 97, Train Loss: 0.4300, Train Acc: 0.8000, Val Loss: 0.6530, Val Acc: 0.6699\n",
      "Epoch 98, Train Loss: 0.4134, Train Acc: 0.8290, Val Loss: 0.6512, Val Acc: 0.6699\n",
      "Epoch 99, Train Loss: 0.4464, Train Acc: 0.7871, Val Loss: 0.6516, Val Acc: 0.6699\n",
      "Epoch 100, Train Loss: 0.4385, Train Acc: 0.8000, Val Loss: 0.6530, Val Acc: 0.6796\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▁▂▂▂▄▃▃▅▄▄▅▄▅▆▆▆▇▆▇▇▇▇▇█▇▇▇▇█▇██▇▇▇▇▇▇▆</td></tr><tr><td>train_loss</td><td>██▇▇▇▇▆▆▆▆▅▅▄▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▂▁▂▂▂▂▁▂</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▅▆▆▄▅▅▇▅▆▅▇▆█▆▇▆▆▇█▆▇▇█▇▇█▇▇█▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▇▆▆▆▅▃▃▃▄▃▃▃▁▄▁▃▃▄▁▃▃▃▄▃▄▄▄▄▄▄▅▄▅▅▄▅▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_eval</td><td>SimpleCNN(<br>  (conv1)...</td></tr><tr><td>train_acc</td><td>0.8</td></tr><tr><td>train_loss</td><td>0.43852</td></tr><tr><td>val_acc</td><td>0.67961</td></tr><tr><td>val_loss</td><td>0.65297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hypothesis-5 SimpleCNN</strong> at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/a1cj9i6x' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/a1cj9i6x</a><br> View project at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250808_155324-a1cj9i6x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model variables definition.\n",
    "pth = \"SimplifiedLightweightCNN.pth\"\n",
    "lr = 4e-5  # Reduce from 1e-3\n",
    "epochs = 100\n",
    "model = model.to(device)\n",
    "reload_function(train)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=2e-4)  # Add L2 regularization\n",
    "# Add learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # name of the run\n",
    "    name=\"Hypothesis-5 SimpleCNN\",\n",
    "    config={\n",
    "        \"Name\": 'SimplifiedLightweightCNN',\n",
    "        \"learning_rate\": lr,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"criterion\": \"BCELoss\",\n",
    "        \"architecture\": \"SimplifiedLightweightCNN\",\n",
    "        \"architecture_details\": str(model),\n",
    "        \"dataset\": \"Stage-I-only-polish\",\n",
    "        \"train_val_test(%)\": f'{TRAIN_SPLIT}-{VAL_SPLIT}-{TEST_SPLIT}',\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    # Logging the metadata for each epoch so that the charts can be generated on the dashboard\n",
    "    run.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, })\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "run.log({\"model_eval\": model.eval()})\n",
    "# Saving the model to pth and adding it to the artifacts of the run, there is 5GB of memory on wandb, so we should be fine.\n",
    "torch.save(model.state_dict(), os.path.join(RESULT_DIRECTORY, pth))\n",
    "artifact = wandb.Artifact(\"SimplifiedLightweightCNN-model\", type=\"model\")\n",
    "artifact.add_file(os.path.join(RESULT_DIRECTORY, pth))\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "# Finish the run so it gets sent to the remote. You can discover the run right after that on the dashboard.\n",
    "run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
