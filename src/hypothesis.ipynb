{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12f8129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:06:49.748097Z",
     "start_time": "2025-07-29T09:06:49.733744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data.source.pg_experiment import get_pg_experiment_dataframe\n",
    "import polars as pl\n",
    "\n",
    "from models.SimplifiedLightweightCNN import SimplifiedLightweightCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport models.SimplifiedLightweightCNN\n",
    "from models.SimpleCNN_v2 import train, evaluate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from path import RESULT_DIRECTORY\n",
    "import wandb\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57adc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.391376Z",
     "start_time": "2025-07-29T09:04:37.356941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 7\n",
      "Number of samples: 3527\n"
     ]
    }
   ],
   "source": [
    "df_pron, df_tone = get_pg_experiment_dataframe(\".ogg\")\n",
    "\n",
    "# Get the target words with val accuracy above 70%\n",
    "TARGET_WORDS = [\"a0\", \"a1\", \"a100\", \"a2\", \"a3\", \"a5\", \"a8\"]\n",
    "dataframe = df_pron.filter(pl.col(\"word_id\").is_in(TARGET_WORDS))\n",
    "\n",
    "dataframe = dataframe.with_columns([\n",
    "    pl.struct(\"word_id\").rank(\"dense\").alias(\"word_id\"),\n",
    "    pl.col(\"value\").cast(pl.Float32) \n",
    "])\n",
    "\n",
    "# Filters\n",
    "dataframe = dataframe.filter((pl.col(\"stage\") == 1))\n",
    "\n",
    "N_WORDS = dataframe.select(pl.col(\"word_id\").n_unique()).item()\n",
    "print(f\"Number of unique words: {N_WORDS}\")\n",
    "print(f\"Number of samples: {dataframe.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a95dcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.442136Z",
     "start_time": "2025-07-29T09:04:37.416770Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def stratified_split(df: pl.DataFrame, label_col: str, train_frac=0.8, val_frac=0.1, seed=42) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    classes = df.select(label_col).unique().to_series()\n",
    "    train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    for cls in classes:\n",
    "        class_df = df.filter(pl.col(label_col) == cls)\n",
    "        n = class_df.height\n",
    "        indices = rng.permutation(n)\n",
    "\n",
    "        train_end = int(train_frac * n)\n",
    "        val_end = int((train_frac + val_frac) * n)\n",
    "\n",
    "        train_rows.append(class_df[indices[:train_end]])\n",
    "        val_rows.append(class_df[indices[train_end:val_end]])\n",
    "        test_rows.append(class_df[indices[val_end:]])\n",
    "\n",
    "    train_df = pl.concat(train_rows)\n",
    "    val_df = pl.concat(val_rows)\n",
    "    test_df = pl.concat(test_rows)\n",
    "\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd331ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:04:37.500687Z",
     "start_time": "2025-07-29T09:04:37.486859Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from polars import DataFrame\n",
    "from dataset import Cast, TorchDataset\n",
    "from develop import reload_function, reload_module\n",
    "import pytorch_dataloader\n",
    "reload_module(pytorch_dataloader)\n",
    "from pytorch_dataloader import ReshapeCollate, build_collate_fn, PaddingCollate, DefaultCollate\n",
    "from functools import partial\n",
    "\n",
    "from transformation import Channels, RMSEnergy, TorchVadLogMelSpec, TorchVadMFCC, ZeroCrossingRate\n",
    "\n",
    "reload_function(TorchVadMFCC)\n",
    "\n",
    "TRAIN_SPLIT = 0.6\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT - VAL_SPLIT\n",
    "train_pl, val_pl, test_pl = stratified_split(dataframe, label_col=\"value\", train_frac=TRAIN_SPLIT, val_frac=VAL_SPLIT)\n",
    "\n",
    "to_dataset: Callable[[DataFrame], TorchDataset] = lambda dataframe: TorchDataset(\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"stack\",\"multiply\")(\n",
    "            TorchVadMFCC(delta=0),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"rec_path\"), Channels(\"cat\",\"multiply\")(\n",
    "            ZeroCrossingRate(),\n",
    "            RMSEnergy(),\n",
    "        )),\n",
    "    Cast(dataframe.get_column(\"word_id\"), lambda x: torch.tensor(x-1, dtype=torch.long)),\n",
    "    Cast(dataframe.get_column(\"value\"), lambda x: torch.tensor(x).float()),\n",
    ")\n",
    "\n",
    "collate_fn = build_collate_fn(\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=80, pad_dim=2),\n",
    "    PaddingCollate(mode=\"SET_MAX_LEN\", max_len=160, pad_dim=1),\n",
    "    DefaultCollate(),\n",
    "    DefaultCollate(),\n",
    ")\n",
    "dataset_train = to_dataset(train_pl)\n",
    "dataset_val = to_dataset(val_pl)\n",
    "dataset_test = to_dataset(test_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be889768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/505/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1059/a2.ogg has no speech segments, using full waveform\n",
      "torch.Size([16, 1, 40, 80])\n",
      "torch.Size([16, 2, 160])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_dataloader import MemoryLoadedDataLoader\n",
    "from os import name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#note, if you are using Windows you MUST set `num_workers=0` - TL;DT multithreading DON'T work in notebooks because Windows DON'T have `fork()`\n",
    "num_workers = 0 if name == \"nt\" else 4\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "for x in next(iter(train_loader)):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf890d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:05:23.032498Z",
     "start_time": "2025-07-29T09:04:37.522932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a3.ogg has no speech segments, using full waveform/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a8.ogg \n",
      "has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/947/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/505/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1366/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/594/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/774/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/411/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a0.ogg has no speech segments, using full waveform/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1460/a2.ogg\n",
      " has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/620/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/655/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a1.ogg \n",
      "has no speech segments, using full waveform/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/697/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/523/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1543/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1021/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/729/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1375/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1059/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/765/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/505/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/61/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1338/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1076/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/589/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a100.ogg has no speech segments, using full waveform\n",
      "Loaded train loader into memory\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/633/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/362/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/354/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/484/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a2.ogg has no speech segments, using full waveform/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/592/a2.ogg\n",
      " has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1536/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/587/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1374/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/659/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/345/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1434/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/385/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/511/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/537/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1363/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1530/a2.ogg has no speech segments, using full waveform\n",
      "Loaded validation loader into memory\n"
     ]
    }
   ],
   "source": [
    "train_loader = MemoryLoadedDataLoader(train_loader, device=device)\n",
    "print(\"Loaded train loader into memory\")\n",
    "val_loader = MemoryLoadedDataLoader(val_loader, device=device)\n",
    "print(\"Loaded validation loader into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91ba076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.FusionCNN import ContextFusionCNN\n",
    "reload_function(ContextFusionCNN)\n",
    "model = ContextFusionCNN(1,2, num_words=N_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0a9fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/kamil2002/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfischbach-kamil\u001b[0m (\u001b[33mfischbach-kamil-pg\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"df5cbdf4ec56162d09c57d7b456e83e24dbd24e1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03a3a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:42.755943Z",
     "start_time": "2025-07-29T09:22:19.522018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/src/wandb/run-20251217_130649-f6zbe0o5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/f6zbe0o5' target=\"_blank\">CFCNN(2) only words with val acc above 70%</a></strong> to <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/f6zbe0o5' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/f6zbe0o5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6827, Train Acc: 0.5650, Val Loss: 0.6767, Val Acc: 0.5623\n",
      "Epoch 2, Train Loss: 0.6793, Train Acc: 0.5726, Val Loss: 0.6705, Val Acc: 0.5680\n",
      "Epoch 3, Train Loss: 0.6761, Train Acc: 0.5702, Val Loss: 0.6656, Val Acc: 0.5708\n",
      "Epoch 4, Train Loss: 0.6689, Train Acc: 0.5712, Val Loss: 0.6564, Val Acc: 0.5850\n",
      "Epoch 5, Train Loss: 0.6633, Train Acc: 0.5825, Val Loss: 0.6492, Val Acc: 0.5878\n",
      "Epoch 6, Train Loss: 0.6617, Train Acc: 0.5868, Val Loss: 0.6420, Val Acc: 0.6048\n",
      "Epoch 7, Train Loss: 0.6564, Train Acc: 0.6151, Val Loss: 0.6323, Val Acc: 0.6261\n",
      "Epoch 8, Train Loss: 0.6476, Train Acc: 0.6227, Val Loss: 0.6245, Val Acc: 0.6416\n",
      "Epoch 9, Train Loss: 0.6460, Train Acc: 0.6047, Val Loss: 0.6201, Val Acc: 0.6785\n",
      "Epoch 10, Train Loss: 0.6395, Train Acc: 0.6241, Val Loss: 0.6123, Val Acc: 0.7139\n",
      "Epoch 11, Train Loss: 0.6370, Train Acc: 0.6350, Val Loss: 0.6082, Val Acc: 0.7096\n",
      "Epoch 12, Train Loss: 0.6278, Train Acc: 0.6525, Val Loss: 0.6015, Val Acc: 0.7040\n",
      "Epoch 13, Train Loss: 0.6259, Train Acc: 0.6454, Val Loss: 0.5947, Val Acc: 0.7125\n",
      "Epoch 14, Train Loss: 0.6293, Train Acc: 0.6388, Val Loss: 0.5947, Val Acc: 0.7025\n",
      "Epoch 15, Train Loss: 0.6208, Train Acc: 0.6600, Val Loss: 0.5876, Val Acc: 0.7082\n",
      "Epoch 16, Train Loss: 0.6213, Train Acc: 0.6657, Val Loss: 0.5857, Val Acc: 0.7096\n",
      "Epoch 17, Train Loss: 0.6159, Train Acc: 0.6662, Val Loss: 0.5838, Val Acc: 0.7054\n",
      "Epoch 18, Train Loss: 0.6034, Train Acc: 0.6780, Val Loss: 0.5759, Val Acc: 0.7110\n",
      "Epoch 19, Train Loss: 0.6121, Train Acc: 0.6799, Val Loss: 0.5774, Val Acc: 0.7139\n",
      "Epoch 20, Train Loss: 0.6093, Train Acc: 0.6738, Val Loss: 0.5752, Val Acc: 0.7110\n",
      "Epoch 21, Train Loss: 0.6004, Train Acc: 0.6832, Val Loss: 0.5732, Val Acc: 0.7110\n",
      "Epoch 22, Train Loss: 0.5994, Train Acc: 0.6870, Val Loss: 0.5673, Val Acc: 0.7167\n",
      "Epoch 23, Train Loss: 0.6027, Train Acc: 0.6946, Val Loss: 0.5691, Val Acc: 0.7153\n",
      "Epoch 24, Train Loss: 0.6074, Train Acc: 0.6761, Val Loss: 0.5731, Val Acc: 0.7096\n",
      "Epoch 25, Train Loss: 0.5977, Train Acc: 0.6950, Val Loss: 0.5696, Val Acc: 0.7096\n",
      "Epoch 26, Train Loss: 0.6019, Train Acc: 0.6804, Val Loss: 0.5687, Val Acc: 0.7195\n",
      "Epoch 27, Train Loss: 0.5965, Train Acc: 0.6927, Val Loss: 0.5633, Val Acc: 0.7224\n",
      "Epoch 28, Train Loss: 0.5985, Train Acc: 0.6917, Val Loss: 0.5645, Val Acc: 0.7224\n",
      "Epoch 29, Train Loss: 0.5937, Train Acc: 0.6941, Val Loss: 0.5659, Val Acc: 0.7181\n",
      "Epoch 30, Train Loss: 0.5919, Train Acc: 0.6960, Val Loss: 0.5617, Val Acc: 0.7337\n",
      "Epoch 31, Train Loss: 0.5923, Train Acc: 0.6950, Val Loss: 0.5607, Val Acc: 0.7351\n",
      "Epoch 32, Train Loss: 0.5961, Train Acc: 0.6979, Val Loss: 0.5614, Val Acc: 0.7380\n",
      "Epoch 33, Train Loss: 0.5873, Train Acc: 0.6898, Val Loss: 0.5607, Val Acc: 0.7351\n",
      "Epoch 34, Train Loss: 0.5928, Train Acc: 0.7092, Val Loss: 0.5576, Val Acc: 0.7351\n",
      "Epoch 35, Train Loss: 0.5915, Train Acc: 0.6974, Val Loss: 0.5587, Val Acc: 0.7380\n",
      "Epoch 36, Train Loss: 0.5865, Train Acc: 0.7040, Val Loss: 0.5588, Val Acc: 0.7394\n",
      "Epoch 37, Train Loss: 0.5844, Train Acc: 0.7064, Val Loss: 0.5534, Val Acc: 0.7394\n",
      "Epoch 38, Train Loss: 0.5843, Train Acc: 0.7007, Val Loss: 0.5545, Val Acc: 0.7465\n",
      "Epoch 39, Train Loss: 0.5824, Train Acc: 0.6946, Val Loss: 0.5550, Val Acc: 0.7380\n",
      "Epoch 40, Train Loss: 0.5836, Train Acc: 0.7026, Val Loss: 0.5521, Val Acc: 0.7422\n",
      "Epoch 41, Train Loss: 0.5841, Train Acc: 0.7007, Val Loss: 0.5543, Val Acc: 0.7280\n",
      "Epoch 42, Train Loss: 0.5826, Train Acc: 0.7035, Val Loss: 0.5551, Val Acc: 0.7337\n",
      "Epoch 43, Train Loss: 0.5833, Train Acc: 0.7111, Val Loss: 0.5493, Val Acc: 0.7465\n",
      "Epoch 44, Train Loss: 0.5790, Train Acc: 0.7116, Val Loss: 0.5509, Val Acc: 0.7408\n",
      "Epoch 45, Train Loss: 0.5778, Train Acc: 0.7173, Val Loss: 0.5465, Val Acc: 0.7450\n",
      "Epoch 46, Train Loss: 0.5801, Train Acc: 0.7125, Val Loss: 0.5478, Val Acc: 0.7436\n",
      "Epoch 47, Train Loss: 0.5847, Train Acc: 0.7078, Val Loss: 0.5489, Val Acc: 0.7365\n",
      "Epoch 48, Train Loss: 0.5790, Train Acc: 0.7050, Val Loss: 0.5490, Val Acc: 0.7436\n",
      "Epoch 49, Train Loss: 0.5767, Train Acc: 0.7121, Val Loss: 0.5484, Val Acc: 0.7394\n",
      "Epoch 50, Train Loss: 0.5757, Train Acc: 0.7050, Val Loss: 0.5510, Val Acc: 0.7309\n",
      "Epoch 51, Train Loss: 0.5765, Train Acc: 0.7154, Val Loss: 0.5492, Val Acc: 0.7408\n",
      "Epoch 52, Train Loss: 0.5661, Train Acc: 0.7177, Val Loss: 0.5454, Val Acc: 0.7394\n",
      "Epoch 53, Train Loss: 0.5656, Train Acc: 0.7239, Val Loss: 0.5436, Val Acc: 0.7365\n",
      "Epoch 54, Train Loss: 0.5671, Train Acc: 0.7182, Val Loss: 0.5442, Val Acc: 0.7365\n",
      "Epoch 55, Train Loss: 0.5600, Train Acc: 0.7196, Val Loss: 0.5433, Val Acc: 0.7394\n",
      "Epoch 56, Train Loss: 0.5678, Train Acc: 0.7158, Val Loss: 0.5464, Val Acc: 0.7337\n",
      "Epoch 57, Train Loss: 0.5732, Train Acc: 0.7130, Val Loss: 0.5469, Val Acc: 0.7337\n",
      "Epoch 58, Train Loss: 0.5712, Train Acc: 0.7158, Val Loss: 0.5441, Val Acc: 0.7323\n",
      "Epoch 59, Train Loss: 0.5643, Train Acc: 0.7177, Val Loss: 0.5431, Val Acc: 0.7408\n",
      "Epoch 60, Train Loss: 0.5626, Train Acc: 0.7210, Val Loss: 0.5413, Val Acc: 0.7394\n",
      "Epoch 61, Train Loss: 0.5686, Train Acc: 0.7243, Val Loss: 0.5402, Val Acc: 0.7436\n",
      "Epoch 62, Train Loss: 0.5701, Train Acc: 0.7281, Val Loss: 0.5408, Val Acc: 0.7380\n",
      "Epoch 63, Train Loss: 0.5590, Train Acc: 0.7291, Val Loss: 0.5429, Val Acc: 0.7337\n",
      "Epoch 64, Train Loss: 0.5720, Train Acc: 0.7196, Val Loss: 0.5401, Val Acc: 0.7380\n",
      "Epoch 65, Train Loss: 0.5663, Train Acc: 0.7239, Val Loss: 0.5384, Val Acc: 0.7507\n",
      "Epoch 66, Train Loss: 0.5649, Train Acc: 0.7182, Val Loss: 0.5382, Val Acc: 0.7351\n",
      "Epoch 67, Train Loss: 0.5689, Train Acc: 0.7173, Val Loss: 0.5384, Val Acc: 0.7337\n",
      "Epoch 68, Train Loss: 0.5594, Train Acc: 0.7371, Val Loss: 0.5380, Val Acc: 0.7309\n",
      "Epoch 69, Train Loss: 0.5585, Train Acc: 0.7182, Val Loss: 0.5366, Val Acc: 0.7436\n",
      "Epoch 70, Train Loss: 0.5664, Train Acc: 0.7182, Val Loss: 0.5393, Val Acc: 0.7323\n",
      "Epoch 71, Train Loss: 0.5617, Train Acc: 0.7329, Val Loss: 0.5358, Val Acc: 0.7436\n",
      "Epoch 72, Train Loss: 0.5604, Train Acc: 0.7272, Val Loss: 0.5371, Val Acc: 0.7323\n",
      "Epoch 73, Train Loss: 0.5500, Train Acc: 0.7428, Val Loss: 0.5348, Val Acc: 0.7408\n",
      "Epoch 74, Train Loss: 0.5550, Train Acc: 0.7267, Val Loss: 0.5353, Val Acc: 0.7380\n",
      "Epoch 75, Train Loss: 0.5595, Train Acc: 0.7296, Val Loss: 0.5377, Val Acc: 0.7337\n",
      "Epoch 76, Train Loss: 0.5453, Train Acc: 0.7409, Val Loss: 0.5363, Val Acc: 0.7323\n",
      "Epoch 77, Train Loss: 0.5502, Train Acc: 0.7400, Val Loss: 0.5345, Val Acc: 0.7323\n",
      "Epoch 78, Train Loss: 0.5575, Train Acc: 0.7220, Val Loss: 0.5355, Val Acc: 0.7309\n",
      "Epoch 79, Train Loss: 0.5555, Train Acc: 0.7348, Val Loss: 0.5352, Val Acc: 0.7394\n",
      "Epoch 80, Train Loss: 0.5470, Train Acc: 0.7314, Val Loss: 0.5353, Val Acc: 0.7394\n",
      "Epoch 81, Train Loss: 0.5646, Train Acc: 0.7324, Val Loss: 0.5317, Val Acc: 0.7436\n",
      "Epoch 82, Train Loss: 0.5483, Train Acc: 0.7385, Val Loss: 0.5331, Val Acc: 0.7422\n",
      "Epoch 83, Train Loss: 0.5465, Train Acc: 0.7310, Val Loss: 0.5337, Val Acc: 0.7337\n",
      "Epoch 84, Train Loss: 0.5607, Train Acc: 0.7348, Val Loss: 0.5317, Val Acc: 0.7408\n",
      "Epoch 85, Train Loss: 0.5483, Train Acc: 0.7433, Val Loss: 0.5301, Val Acc: 0.7309\n",
      "Epoch 86, Train Loss: 0.5481, Train Acc: 0.7348, Val Loss: 0.5300, Val Acc: 0.7351\n",
      "Epoch 87, Train Loss: 0.5560, Train Acc: 0.7243, Val Loss: 0.5322, Val Acc: 0.7380\n",
      "Epoch 88, Train Loss: 0.5501, Train Acc: 0.7338, Val Loss: 0.5308, Val Acc: 0.7337\n",
      "Epoch 89, Train Loss: 0.5474, Train Acc: 0.7277, Val Loss: 0.5323, Val Acc: 0.7309\n",
      "Epoch 90, Train Loss: 0.5568, Train Acc: 0.7215, Val Loss: 0.5285, Val Acc: 0.7351\n",
      "Epoch 91, Train Loss: 0.5450, Train Acc: 0.7409, Val Loss: 0.5287, Val Acc: 0.7365\n",
      "Epoch 92, Train Loss: 0.5497, Train Acc: 0.7381, Val Loss: 0.5277, Val Acc: 0.7337\n",
      "Epoch 93, Train Loss: 0.5531, Train Acc: 0.7376, Val Loss: 0.5261, Val Acc: 0.7436\n",
      "Epoch 94, Train Loss: 0.5468, Train Acc: 0.7296, Val Loss: 0.5284, Val Acc: 0.7380\n",
      "Epoch 95, Train Loss: 0.5409, Train Acc: 0.7329, Val Loss: 0.5297, Val Acc: 0.7309\n",
      "Epoch 96, Train Loss: 0.5476, Train Acc: 0.7423, Val Loss: 0.5269, Val Acc: 0.7351\n",
      "Epoch 97, Train Loss: 0.5493, Train Acc: 0.7428, Val Loss: 0.5250, Val Acc: 0.7309\n",
      "Epoch 98, Train Loss: 0.5401, Train Acc: 0.7343, Val Loss: 0.5258, Val Acc: 0.7323\n",
      "Epoch 99, Train Loss: 0.5450, Train Acc: 0.7447, Val Loss: 0.5260, Val Acc: 0.7337\n",
      "Epoch 100, Train Loss: 0.5471, Train Acc: 0.7343, Val Loss: 0.5251, Val Acc: 0.7309\n",
      "Epoch 101, Train Loss: 0.5439, Train Acc: 0.7362, Val Loss: 0.5236, Val Acc: 0.7337\n",
      "Epoch 102, Train Loss: 0.5415, Train Acc: 0.7532, Val Loss: 0.5256, Val Acc: 0.7323\n",
      "Epoch 103, Train Loss: 0.5292, Train Acc: 0.7527, Val Loss: 0.5265, Val Acc: 0.7280\n",
      "Epoch 104, Train Loss: 0.5449, Train Acc: 0.7400, Val Loss: 0.5234, Val Acc: 0.7323\n",
      "Epoch 105, Train Loss: 0.5310, Train Acc: 0.7423, Val Loss: 0.5214, Val Acc: 0.7266\n",
      "Epoch 106, Train Loss: 0.5346, Train Acc: 0.7437, Val Loss: 0.5206, Val Acc: 0.7295\n",
      "Epoch 107, Train Loss: 0.5353, Train Acc: 0.7414, Val Loss: 0.5191, Val Acc: 0.7266\n",
      "Epoch 108, Train Loss: 0.5410, Train Acc: 0.7310, Val Loss: 0.5194, Val Acc: 0.7351\n",
      "Epoch 109, Train Loss: 0.5395, Train Acc: 0.7456, Val Loss: 0.5196, Val Acc: 0.7365\n",
      "Epoch 110, Train Loss: 0.5360, Train Acc: 0.7456, Val Loss: 0.5173, Val Acc: 0.7323\n",
      "Epoch 111, Train Loss: 0.5372, Train Acc: 0.7466, Val Loss: 0.5234, Val Acc: 0.7337\n",
      "Epoch 112, Train Loss: 0.5283, Train Acc: 0.7504, Val Loss: 0.5173, Val Acc: 0.7252\n",
      "Epoch 113, Train Loss: 0.5314, Train Acc: 0.7579, Val Loss: 0.5156, Val Acc: 0.7323\n",
      "Epoch 114, Train Loss: 0.5275, Train Acc: 0.7518, Val Loss: 0.5146, Val Acc: 0.7351\n",
      "Epoch 115, Train Loss: 0.5326, Train Acc: 0.7385, Val Loss: 0.5172, Val Acc: 0.7309\n",
      "Epoch 116, Train Loss: 0.5345, Train Acc: 0.7518, Val Loss: 0.5142, Val Acc: 0.7465\n",
      "Epoch 117, Train Loss: 0.5272, Train Acc: 0.7404, Val Loss: 0.5138, Val Acc: 0.7450\n",
      "Epoch 118, Train Loss: 0.5248, Train Acc: 0.7423, Val Loss: 0.5230, Val Acc: 0.7238\n",
      "Epoch 119, Train Loss: 0.5068, Train Acc: 0.7565, Val Loss: 0.5164, Val Acc: 0.7323\n",
      "Epoch 120, Train Loss: 0.5322, Train Acc: 0.7404, Val Loss: 0.5135, Val Acc: 0.7309\n",
      "Epoch 121, Train Loss: 0.5246, Train Acc: 0.7603, Val Loss: 0.5129, Val Acc: 0.7280\n",
      "Epoch 122, Train Loss: 0.5272, Train Acc: 0.7518, Val Loss: 0.5117, Val Acc: 0.7337\n",
      "Epoch 123, Train Loss: 0.5248, Train Acc: 0.7418, Val Loss: 0.5141, Val Acc: 0.7351\n",
      "Epoch 124, Train Loss: 0.5239, Train Acc: 0.7485, Val Loss: 0.5112, Val Acc: 0.7323\n",
      "Epoch 125, Train Loss: 0.5185, Train Acc: 0.7518, Val Loss: 0.5178, Val Acc: 0.7337\n",
      "Epoch 126, Train Loss: 0.5254, Train Acc: 0.7593, Val Loss: 0.5160, Val Acc: 0.7295\n",
      "Epoch 127, Train Loss: 0.5179, Train Acc: 0.7589, Val Loss: 0.5134, Val Acc: 0.7309\n",
      "Epoch 128, Train Loss: 0.5154, Train Acc: 0.7513, Val Loss: 0.5078, Val Acc: 0.7351\n",
      "Epoch 129, Train Loss: 0.5147, Train Acc: 0.7622, Val Loss: 0.5106, Val Acc: 0.7365\n",
      "Epoch 130, Train Loss: 0.5226, Train Acc: 0.7527, Val Loss: 0.5069, Val Acc: 0.7351\n",
      "Epoch 131, Train Loss: 0.5102, Train Acc: 0.7513, Val Loss: 0.5077, Val Acc: 0.7351\n",
      "Epoch 132, Train Loss: 0.5028, Train Acc: 0.7721, Val Loss: 0.5065, Val Acc: 0.7394\n",
      "Epoch 133, Train Loss: 0.5206, Train Acc: 0.7702, Val Loss: 0.5054, Val Acc: 0.7394\n",
      "Epoch 134, Train Loss: 0.5155, Train Acc: 0.7603, Val Loss: 0.5083, Val Acc: 0.7323\n",
      "Epoch 135, Train Loss: 0.5169, Train Acc: 0.7593, Val Loss: 0.5032, Val Acc: 0.7422\n",
      "Epoch 136, Train Loss: 0.5077, Train Acc: 0.7574, Val Loss: 0.5066, Val Acc: 0.7323\n",
      "Epoch 137, Train Loss: 0.5132, Train Acc: 0.7565, Val Loss: 0.5064, Val Acc: 0.7323\n",
      "Epoch 138, Train Loss: 0.5065, Train Acc: 0.7664, Val Loss: 0.5055, Val Acc: 0.7450\n",
      "Epoch 139, Train Loss: 0.4997, Train Acc: 0.7712, Val Loss: 0.5050, Val Acc: 0.7493\n",
      "Epoch 140, Train Loss: 0.5072, Train Acc: 0.7693, Val Loss: 0.5034, Val Acc: 0.7493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▄▄▅▅▅▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▇▇▅▅▅▅▄▄▄▄▄▄▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▄▅▆▆▇▇██████▇██▇▇██▇█▇▇████▇▇▇▇▇██▇█▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_eval</td><td>ContextFusionCNN(<br>  ...</td></tr><tr><td>train_acc</td><td>0.76927</td></tr><tr><td>train_loss</td><td>0.50721</td></tr><tr><td>val_acc</td><td>0.74929</td></tr><tr><td>val_loss</td><td>0.50336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CFCNN(2) only words with val acc above 70%</strong> at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/f6zbe0o5' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src/runs/f6zbe0o5</a><br> View project at: <a href='https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src' target=\"_blank\">https://wandb.ai/fischbach-kamil-pg/Mandarin_Pronunciation_Recognition_Project-src</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251217_130649-f6zbe0o5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model variables definition.\n",
    "pth = \"ContextFusionCNN.pth\"\n",
    "lr = 1e-4  # Reduce from 1e-3\n",
    "epochs = 140\n",
    "model = model.to(device)\n",
    "reload_function(train)\n",
    "reload_function(evaluate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)  # Add L2 regularization\n",
    "# Add learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # name of the run\n",
    "    name=\"CFCNN(2) only words with val acc above 70%\",\n",
    "    config={\n",
    "        \"Name\": 'ContextFusionCNN',\n",
    "        \"learning_rate\": lr,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"criterion\": \"BCELoss\",\n",
    "        \"architecture\": \"ContextFusionCNN\",\n",
    "        \"architecture_details\": str(model),\n",
    "        \"dataset\": \"Stage-I-minimized\",\n",
    "        \"train_val_test(%)\": f'{TRAIN_SPLIT}-{VAL_SPLIT}-{TEST_SPLIT}',\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    # Logging the metadata for each epoch so that the charts can be generated on the dashboard\n",
    "    run.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, })\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "run.log({\"model_eval\": model.eval()})\n",
    "# Saving the model to pth and adding it to the artifacts of the run, there is 5GB of memory on wandb, so we should be fine.\n",
    "torch.save(model.state_dict(), os.path.join(RESULT_DIRECTORY, pth))\n",
    "artifact = wandb.Artifact(\"SimplifiedLightweightCNN-model\", type=\"model\")\n",
    "artifact.add_file(os.path.join(RESULT_DIRECTORY, pth))\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "# Finish the run so it gets sent to the remote. You can discover the run right after that on the dashboard.\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4397fcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/550/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/620/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/489/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/772/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/668/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1297/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/632/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/664/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/592/a3.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/761/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1349/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1293/a100.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/612/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/944/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/456/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/493/a0.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1093/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1024/a8.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/765/a1.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1544/a2.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/1300/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/744/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/500/a5.ogg has no speech segments, using full waveform\n",
      "/home/kamil2002/Mandarin_Pronunciation_Recognition_Project/data/source/pg_dataset/recordings/stageI/706/a5.ogg has no speech segments, using full waveform\n",
      "Loaded test loader into memory\n"
     ]
    }
   ],
   "source": [
    "test_loader = MemoryLoadedDataLoader(test_loader, device=device)\n",
    "print(\"Loaded test loader into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a408b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FINAL TEST RESULTS\n",
      "Test Loss: 0.5561\n",
      "Test Accuracy: 0.7195\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"FINAL TEST RESULTS\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mandarin_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
